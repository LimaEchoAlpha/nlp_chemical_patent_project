{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train_test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train_test.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def train_test_split(all_lists):\n",
    "    \"\"\"\n",
    "    Quick and dirty code for doing a train/test split on sample data\n",
    "    adopted from BERT_T5_NER_2_3_030521 notebook from office hours\n",
    "    \"\"\"\n",
    "    \n",
    "    numSentences = len(all_lists[0][0])\n",
    "    np.random.seed(424)\n",
    "    training_examples = np.random.binomial(1, 0.7, numSentences)\n",
    "    \n",
    "    trainSentence_ids = []\n",
    "    trainMasks = []\n",
    "    trainSequence_ids = []\n",
    "    trainE1Masks = []\n",
    "    trainE2Masks = []\n",
    "\n",
    "    testSentence_ids = []\n",
    "    testMasks = []\n",
    "    testSequence_ids = []\n",
    "    testE1Masks = []\n",
    "    testE2Masks = []\n",
    "\n",
    "    labels_train =[]\n",
    "    labels_test = []\n",
    "\n",
    "    for example in range(numSentences):\n",
    "        if training_examples[example] == 1:\n",
    "            trainSentence_ids.append(all_lists[0][0][example])\n",
    "            trainMasks.append(all_lists[0][1][example])\n",
    "            trainSequence_ids.append(all_lists[0][2][example])\n",
    "            trainE1Masks.append(all_lists[0][3][example])\n",
    "            trainE2Masks.append(all_lists[0][4][example])\n",
    "            labels_train.append(all_lists[1][example])\n",
    "        else:\n",
    "            testSentence_ids.append(all_lists[0][0][example])\n",
    "            testMasks.append(all_lists[0][1][example])\n",
    "            testSequence_ids.append(all_lists[0][2][example])\n",
    "            testE1Masks.append(all_lists[0][3][example])\n",
    "            testE2Masks.append(all_lists[0][4][example])\n",
    "            labels_test.append(all_lists[1][example])\n",
    "\n",
    "    X_train = [np.array(trainSentence_ids), np.array(trainMasks), np.array(trainSequence_ids), \n",
    "               np.array(trainE1Masks), np.array(trainE2Masks)]\n",
    "    X_test = [np.array(testSentence_ids), np.array(testMasks), np.array(testSequence_ids), \n",
    "              np.array(testE1Masks), np.array(testE2Masks)]\n",
    "\n",
    "    reLabels_train = np.array(labels_train)\n",
    "    reLabels_test = np.array(labels_test)\n",
    "    \n",
    "    train_all = [X_train, reLabels_train]\n",
    "    test_all = [X_test, reLabels_test]\n",
    "    \n",
    "    return train_all, test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMbXeVp7ZkpXlI1z13KHxK1",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1ncM7IFEgM8vhjwuZRLUJBL3L9Bh-70pS",
   "name": "baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "from string import punctuation\n",
    "from time import time\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from statistics import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lea/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ann(ann_file):\n",
    "    \"\"\"Helper function that reads a .ann file,\n",
    "       strips out newline characters, splits the tab-delimited entries,\n",
    "       and extracts information for identifying entities and relations \n",
    "       in corresponding .txt file\n",
    "       \n",
    "       Input:\n",
    "       ann_file = tab-delimited brat annotation file with the following format\n",
    "                  NER: [entity_ID]\\t[label start_offset end_offset]\\t[entity]\n",
    "                  RE:  [relation_ID]\\t[relation_type argument1 argument2]\n",
    "       \n",
    "       Outputs:\n",
    "       cleaned_offsets = list of tuples for labeling corresponding .txt file\n",
    "                         format: (offset, label, entity ID)\n",
    "       relations = list of tuples for extracting relations from corresponding .txt file\n",
    "                   format: (relation ID, relation_type, entity ID #1, entity ID #2)\"\"\"\n",
    "    \n",
    "    with io.open(ann_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = [x.strip().split('\\t') for x in f.readlines()]\n",
    "        \n",
    "    ann = [x for x in text if x[0][0] == 'T']\n",
    "    rel = [x for x in text if x[0][0] == 'R']\n",
    "    \n",
    "    # extract information for identifying entities\n",
    "    offsets = []\n",
    "    \n",
    "    for x in ann:\n",
    "        entity_id = x[0]\n",
    "        start = int(x[1].split()[1])\n",
    "        end = int(x[1].split()[2])\n",
    "        label = x[1].split()[0]\n",
    "        \n",
    "        offsets.append((start, 'S', label, entity_id))\n",
    "        offsets.append((end, 'E', label, entity_id))\n",
    "    \n",
    "    # sort offsets and clean overlapping entries\n",
    "    sorted_offsets = sorted(offsets, key=lambda x:x[0])\n",
    "    \n",
    "    cleaned_offsets = []\n",
    "    corrections = {}\n",
    "    \n",
    "    hold = None\n",
    "    indicator = None\n",
    "    \n",
    "    for tup in sorted_offsets:\n",
    "        \n",
    "        if indicator == 'S':\n",
    "            if tup[1] == 'E':\n",
    "                cleaned_offsets.append(hold)\n",
    "                hold = (tup[0], 'O', 'X')\n",
    "                indicator = tup[1]\n",
    "            elif tup[1] == 'S':\n",
    "                corrections.update({tup[3]:hold[2]})\n",
    "                indicator = '*'\n",
    "        \n",
    "        elif indicator == 'E':\n",
    "            cleaned_offsets.append(hold)\n",
    "            hold = (tup[0], tup[2], tup[3])\n",
    "            indicator = tup[1]\n",
    "        \n",
    "        elif indicator == '*':\n",
    "            indicator = 'S'\n",
    "\n",
    "        else:\n",
    "            hold = (tup[0], tup[2], tup[3])\n",
    "            indicator = tup[1]\n",
    "            \n",
    "    cleaned_offsets.append(hold)\n",
    "    \n",
    "    # extract information for identifying relations\n",
    "    relations = []\n",
    "    \n",
    "    for r in rel:\n",
    "        relation_id = r[0]\n",
    "        relation_type = r[1].split()[0]\n",
    "        entity1 = r[1].split()[1][5:]\n",
    "        entity2 = r[1].split()[2][5:]\n",
    "        \n",
    "        if entity1 in corrections.keys():\n",
    "            entity1 = corrections[entity1]\n",
    "        if entity2 in corrections.keys():\n",
    "            entity2 = corrections[entity2]\n",
    "        \n",
    "        relations.append((relation_id, relation_type, entity1, entity2))\n",
    "    \n",
    "    return cleaned_offsets, relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '../raw_data/sample_ee/0003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Example 51-5 : Preparation of 2'-amino-6-(2-amino-6-morpholinopyrimidin-4-yl)-3'-fluoro-[2,4'-bipyridin]-5-ol (LXXVI)\\n6-(2-Amino-6-morpholinopyrimidin-4-yl)-3'-fluoro-5-methoxy-[2,4'-bipyridin]-2'-amine (120 mg, 301.95 µmol) and pyridine hydrochloride (Pyridine HCl) (523.41 mg, 4.53 mmol) were stirred in a sealed tube at 170 °C for 30 min. The resulting mixture was cooled to room temperature, neutralized with 2 N NaOH solution to provide a solid. The solid was filtered, washed with diethylether and dried to give the title compound (72 mg, 62 %).\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with io.open(f'{test_path}.txt', 'r', encoding='utf-8', errors='ignore') as text:\n",
    "    full_text = text.read()\n",
    "full_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['T0', 'TIME 334 340', '30 min'],\n",
       " ['T1', 'TEMPERATURE 378 394', 'room temperature'],\n",
       " ['T2', 'YIELD_PERCENT 545 549', '62 %']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with io.open(f'{test_path}.ann', 'r', encoding='utf-8', errors='ignore') as text:\n",
    "    ann = [x.strip().split('\\t') for x in text.readlines()] #if x.strip().split('\\t')[0][0] == 'R']\n",
    "ann[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_offsets, test_relations = process_ann(f'{test_path}.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 'EXAMPLE_LABEL', 'T9'), (12, 'O', 'X'), (30, 'REACTION_PRODUCT', 'T7')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_offsets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('R0', 'ARG1', 'T14', 'T13'),\n",
       " ('R1', 'ARG1', 'T15', 'T12'),\n",
       " ('R2', 'ARGM', 'T15', 'T6')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_relations[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train files: 900\n"
     ]
    }
   ],
   "source": [
    "path_train = '../raw_data/EE/ee_train'\n",
    "filenames_train = list({x[:4] for x in os.listdir(path_train) if x[0] != '.'})\n",
    "print(f'Number of train files: {len(filenames_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_relations = []\n",
    "unique_triggers = []\n",
    "entities = []\n",
    "example_labels = []\n",
    "example_check = []\n",
    "pairs_per_trigger = []\n",
    "before_count = []\n",
    "span_before = []\n",
    "after_count = []\n",
    "span_after = []\n",
    "\n",
    "for file in filenames_train:\n",
    "    \n",
    "    offsets, relations = process_ann(f'{path_train}/{file}.ann')\n",
    "    \n",
    "    # how many positive relations per snippet?\n",
    "    positive_relations.append(len(relations))\n",
    "    \n",
    "    # how many unique trigger words per snippet?\n",
    "    arg1 = {x[2] for x in relations}\n",
    "    unique_triggers.append(len(arg1))\n",
    "    \n",
    "    arg2 = {x[3] for x in relations}\n",
    "    example = []\n",
    "    for x in offsets:\n",
    "        if x[1] == 'EXAMPLE_LABEL':\n",
    "            example.append(x[2])\n",
    "    \n",
    "    # how many example labels per snippet?\n",
    "    example_labels.append(len(example))\n",
    "    \n",
    "    # is example label ever in a relation?\n",
    "    for x in example:\n",
    "        if x in arg2:\n",
    "            example_check.append(1)\n",
    "        else:\n",
    "            example_check.append(0)\n",
    "    \n",
    "    # how many pairs per trigger word?\n",
    "    for x in arg1:\n",
    "        count = [1 for r in relations if r[2] == x]\n",
    "        pairs_per_trigger.append(len(count))\n",
    "        \n",
    "    # what is the span?\n",
    "    entity_order = [x[2] for x in offsets if (x[2] != 'X' and x[1] != 'EXAMPLE_LABEL')]\n",
    "    entities.append(len(entity_order))\n",
    "    \n",
    "    for x in arg1:\n",
    "        index = entity_order.index(x)\n",
    "        rels = [entity_order.index(r[3]) for r in relations if r[2] == x]\n",
    "        \n",
    "        bf = [x for x in rels if x < index]\n",
    "        if bf:\n",
    "            before_count.append(len(bf))\n",
    "            span = index - min(bf)\n",
    "            span_before.append(span)\n",
    "        \n",
    "        af = [x for x in rels if x > index]\n",
    "        if af:\n",
    "            after_count.append(len(af))\n",
    "            span = max(af) - index\n",
    "            span_after.append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is example label ever in a relation? {0}\n",
      "Max example labels in train set: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Is example label ever in a relation? {set(example_check)}')\n",
    "print(f'Max example labels in train set: {max(example_labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive relations in train set: 14310\n",
      "\n",
      "Total unique trigger words in train set: 6852\n",
      "Total number of entities in train set (excluding EXAMPLE_LABEL): 22297\n",
      "\n",
      "Median unique trigger words in train set: 7.0\n",
      "Average unique trigger words in train set: 7.6\n",
      "Max unique trigger words in train set: 62\n",
      "\n",
      "Median pairs per trigger word in train set: 2.0\n",
      "Average pairs per trigger word in train set: 2.1\n",
      "Max pairs per trigger word in train set: 13\n",
      "\n",
      "Median entities in train set: 24.0\n",
      "Average entities in train set: 24.8\n",
      "Max entities in train set: 182\n"
     ]
    }
   ],
   "source": [
    "print(f'Total positive relations in train set: {sum(positive_relations)}')\n",
    "print()\n",
    "print(f'Total unique trigger words in train set: {sum(unique_triggers)}')\n",
    "print(f'Total number of entities in train set (excluding EXAMPLE_LABEL): {sum(entities)}')\n",
    "print()\n",
    "print(f'Median unique trigger words in train set: {median(unique_triggers):.1f}')\n",
    "print(f'Average unique trigger words in train set: {mean(unique_triggers):.1f}')\n",
    "print(f'Max unique trigger words in train set: {max(unique_triggers)}')\n",
    "print()\n",
    "print(f'Median pairs per trigger word in train set: {median(pairs_per_trigger):.1f}')\n",
    "print(f'Average pairs per trigger word in train set: {mean(pairs_per_trigger):.1f}')\n",
    "print(f'Max pairs per trigger word in train set: {max(pairs_per_trigger)}')\n",
    "print()\n",
    "print(f'Median entities in train set: {median(entities):.1f}')\n",
    "print(f'Average entities in train set: {mean(entities):.1f}')\n",
    "print(f'Max entities in train set: {max(entities)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of pairs   count\n",
      "    1        2985\n",
      "    2        1674\n",
      "    3        1395\n",
      "    4        410\n",
      "    5        253\n",
      "    6        92\n",
      "    7        24\n",
      "    8        14\n",
      "    9        1\n",
      "    10       2\n",
      "    11       0\n",
      "    12       0\n",
      "    13       2\n"
     ]
    }
   ],
   "source": [
    "print('# of pairs   count')\n",
    "\n",
    "for i in range(max(pairs_per_trigger)):\n",
    "    count = [1 for x in pairs_per_trigger if x == (i+1)]\n",
    "    print(f'{(i+1):^10}   {len(count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median entities before trigger word in train set: 2.0\n",
      "Average entities before trigger word in train set: 1.8\n",
      "Max entities before trigger word in train set: 8\n",
      "\n",
      "Median entities after trigger word in train set: 2.0\n",
      "Average entities after trigger word in train set: 1.8\n",
      "Max entities after trigger word in train set: 13\n"
     ]
    }
   ],
   "source": [
    "print(f'Median entities before trigger word in train set: {median(before_count):.1f}')\n",
    "print(f'Average entities before trigger word in train set: {mean(before_count):.1f}')\n",
    "print(f'Max entities before trigger word in train set: {max(before_count)}')\n",
    "print()\n",
    "print(f'Median entities after trigger word in train set: {median(after_count):.1f}')\n",
    "print(f'Average entities after trigger word in train set: {mean(after_count):.1f}')\n",
    "print(f'Max entities after trigger word in train set: {max(after_count)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trigger words with more than 5 linked entities before: 17\n",
      "Number of trigger words with more than 5 linked entities after: 16\n"
     ]
    }
   ],
   "source": [
    "more_than_before = [x for x in before_count if x > 5]\n",
    "more_than_after = [x for x in after_count if x > 5]\n",
    "\n",
    "print(f'Number of trigger words with more than 5 linked entities before: {len(more_than_before)}')\n",
    "print(f'Number of trigger words with more than 5 linked entities after: {len(more_than_after)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median span before trigger word in train set: 2.0\n",
      "Average span before trigger word in train set: 1.9\n",
      "Max span before trigger word in train set: 8\n",
      "\n",
      "Median span after trigger word in train set: 2.0\n",
      "Average span after trigger word in train set: 1.8\n",
      "Max span after trigger word in train set: 13\n"
     ]
    }
   ],
   "source": [
    "print(f'Median span before trigger word in train set: {median(span_before):.1f}')\n",
    "print(f'Average span before trigger word in train set: {mean(span_before):.1f}')\n",
    "print(f'Max span before trigger word in train set: {max(span_before)}')\n",
    "print()\n",
    "print(f'Median span after trigger word in train set: {median(span_after):.1f}')\n",
    "print(f'Average span after trigger word in train set: {mean(span_after):.1f}')\n",
    "print(f'Max span after trigger word in train set: {max(span_after)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trigger words with span more than 5 linked entities before: 18\n",
      "Number of trigger words with span more than 5 linked entities after: 26\n"
     ]
    }
   ],
   "source": [
    "span_more_than_before = [x for x in span_before if x > 5]\n",
    "span_more_than_after = [x for x in span_after if x > 5]\n",
    "\n",
    "print(f'Number of trigger words with span more than 5 linked entities before: {len(span_more_than_before)}')\n",
    "print(f'Number of trigger words with span more than 5 linked entities after: {len(span_more_than_after)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relations left out: 77\n",
      "Fraction left out: 0.005\n"
     ]
    }
   ],
   "source": [
    "before_leftout = [x-5 for x in span_more_than_before]\n",
    "after_leftout = [x-5 for x in span_more_than_after]\n",
    "\n",
    "total_leftout = sum(before_leftout) + sum(after_leftout)\n",
    "fraction_leftout = total_leftout / sum(positive_relations)\n",
    "\n",
    "print(f'Number of relations left out: {total_leftout}')\n",
    "print(f'Fraction left out: {fraction_leftout:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA revisted with updated processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ann2(ann_file):\n",
    "    \"\"\"Helper function that reads a .ann file,\n",
    "       strips out newline characters, splits the tab-delimited entries,\n",
    "       and extracts information for identifying entities and relations \n",
    "       in corresponding .txt file.\n",
    "       Also adds negative relations within the span of +/- entities \n",
    "       from each trigger word.\n",
    "       \n",
    "       Input:\n",
    "       ann_file = tab-delimited brat annotation file with the following format\n",
    "                  NER: [entity_ID]\\t[label start_offset end_offset]\\t[entity]\n",
    "                  RE:  [relation_ID]\\t[relation_type argument1 argument2]\n",
    "       \n",
    "       Outputs:\n",
    "       cleaned_offsets = list of tuples for labeling corresponding .txt file\n",
    "                         format: (offset, label, entity ID)\n",
    "       relations = list of tuples for extracting relations from corresponding .txt file\n",
    "                   format: (relation ID, relation_type, entity ID #1, entity ID #2)\"\"\"\n",
    "    \n",
    "    with io.open(ann_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = [x.strip().split('\\t') for x in f.readlines()]\n",
    "        \n",
    "    ann = [x for x in text if x[0][0] == 'T']\n",
    "    rel = [x for x in text if x[0][0] == 'R']\n",
    "    \n",
    "    # extract information for identifying entities\n",
    "    offsets = []\n",
    "    \n",
    "    for x in ann:\n",
    "        entity_id = x[0]\n",
    "        start = int(x[1].split()[1])\n",
    "        end = int(x[1].split()[2])\n",
    "        label = x[1].split()[0]\n",
    "        \n",
    "        offsets.append((start, 'S', label, entity_id))\n",
    "        offsets.append((end, 'E', label, entity_id))\n",
    "    \n",
    "    # sort offsets and clean overlapping entries\n",
    "    sorted_offsets = sorted(offsets, key=lambda x:x[0])\n",
    "    \n",
    "    cleaned_offsets = []\n",
    "    corrections = {}\n",
    "    \n",
    "    hold = None\n",
    "    indicator = None\n",
    "    \n",
    "    for tup in sorted_offsets:\n",
    "        \n",
    "        if indicator == 'S':\n",
    "            if tup[1] == 'E':\n",
    "                cleaned_offsets.append(hold)\n",
    "                hold = (tup[0], 'O', 'X')\n",
    "                indicator = tup[1]\n",
    "            elif tup[1] == 'S':\n",
    "                corrections.update({tup[3]:hold[2]})\n",
    "                indicator = '*'\n",
    "        \n",
    "        elif indicator == 'E':\n",
    "            cleaned_offsets.append(hold)\n",
    "            hold = (tup[0], tup[2], tup[3])\n",
    "            indicator = tup[1]\n",
    "        \n",
    "        elif indicator == '*':\n",
    "            indicator = 'S'\n",
    "\n",
    "        else:\n",
    "            hold = (tup[0], tup[2], tup[3])\n",
    "            indicator = tup[1]\n",
    "            \n",
    "    cleaned_offsets.append(hold)\n",
    "    \n",
    "    # extract information for identifying relations\n",
    "    relations = []\n",
    "    positives = []\n",
    "    \n",
    "    # add positive relations\n",
    "    for r in rel:\n",
    "        relation_id = r[0]\n",
    "        relation_type = r[1].split()[0]\n",
    "        entity1 = r[1].split()[1][5:]\n",
    "        entity2 = r[1].split()[2][5:]\n",
    "        \n",
    "        if entity1 in corrections.keys():\n",
    "            entity1 = corrections[entity1]\n",
    "        if entity2 in corrections.keys():\n",
    "            entity2 = corrections[entity2]\n",
    "        \n",
    "        relations.append((relation_id, relation_type, entity1, entity2))\n",
    "        positives.append((entity1, entity2))\n",
    "    \n",
    "    # negative relations\n",
    "    negatives = []\n",
    "    triggers = {x[2] for x in cleaned_offsets if (x[1] == 'WORKUP' or x[1] == 'REACTION_STEP')}\n",
    "    entity_order = [x[2] for x in cleaned_offsets if (x[2] != 'X' and x[1] != 'EXAMPLE_LABEL')]\n",
    "    trigger_indices = {entity_order.index(x) for x in triggers}\n",
    "    \n",
    "    # find negative relations\n",
    "    for t in triggers:\n",
    "        index = entity_order.index(t)\n",
    "        \n",
    "        # find indices in span of +/- 5 from trigger\n",
    "        find_span = [index - (i+1) for i in range(5)] + [index + (i+1) for i in range(5)]\n",
    "        real_span = [i for i in find_span if (i >= 0 and i < len(entity_order))]\n",
    "        span = [i for i in real_span if i not in trigger_indices]\n",
    "        \n",
    "        # make tuples of trigger words and entities from span indices\n",
    "        potential_pairs = [(t, entity_order[i]) for i in span]\n",
    "        \n",
    "        # check if tuple is in positives\n",
    "        # only add to negatives if not in positives\n",
    "        for pair in potential_pairs:\n",
    "            if pair in positives:\n",
    "                continue\n",
    "            else:\n",
    "                negatives.append(pair)\n",
    "    \n",
    "    # make a list of negative relations \n",
    "    # in same format as positives to add to relations list\n",
    "    i = 0\n",
    "    for pair in negatives:\n",
    "        negative_id = f'N{i}'\n",
    "        relations.append((negative_id, 'NONE', pair[0], pair[1]))\n",
    "        i += 1\n",
    "    \n",
    "    return cleaned_offsets, relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_relations = []\n",
    "\n",
    "for file in filenames_train:\n",
    "    \n",
    "    offsets, relations = process_ann2(f'{path_train}/{file}.ann')\n",
    "    negatives = [1 for x in relations if x[0][0] == 'N']\n",
    "    negative_relations.append(len(negatives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total negative relations in train set: 31511\n",
      "\n",
      "Median negative relations in train set: 34.0\n",
      "Average negative relations in train set: 35.0\n",
      "Max negative relations in train set: 314\n"
     ]
    }
   ],
   "source": [
    "print(f'Total negative relations in train set: {sum(negative_relations)}')\n",
    "print()\n",
    "print(f'Median negative relations in train set: {median(negative_relations):.1f}')\n",
    "print(f'Average negative relations in train set: {mean(negative_relations):.1f}')\n",
    "print(f'Max negative relations in train set: {max(negative_relations)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated snippet lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_chunker(txt_file, offsets):\n",
    "    \"\"\"Helper function that reads in a .txt file as one string,\n",
    "       divides it based on the cleaned offsets from its .ann file\n",
    "       and labels chunks with NER tags\n",
    "       \n",
    "       Inputs:\n",
    "       txt_file = file that contains all the patent text\n",
    "                  considered as one sentence in this task\n",
    "       offsets = list of tuples for labeling corresponding .txt file\n",
    "                 format: (offset, label, entity ID)\n",
    "       \n",
    "       Output:\n",
    "       ann_chunks = list of annotated chunks based on .ann file offsets\n",
    "                    format: (chunk, label, entity ID)\"\"\"\n",
    "    \n",
    "    with io.open(txt_file, 'r', encoding='utf-8', errors='ignore') as text:\n",
    "        full_text = text.read()\n",
    "    \n",
    "    start = 0\n",
    "    end = offsets[0][0]\n",
    "    label = 'O'\n",
    "    entity_id = 'X'\n",
    "    \n",
    "    ann_chunks = [(full_text[:end], label, entity_id)]\n",
    "    \n",
    "    for i in range(len(offsets)):\n",
    "        start = offsets[i][0]\n",
    "        label = offsets[i][1]\n",
    "        entity_id = offsets[i][2]\n",
    "        \n",
    "        if i < len(offsets) - 1:\n",
    "            end = offsets[i+1][0]\n",
    "            term = [(full_text[start:end], label, entity_id)]\n",
    "            if term[0]:\n",
    "                ann_chunks.extend(term)\n",
    "        \n",
    "        else:\n",
    "            term = [(full_text[start:], label, entity_id)]  \n",
    "            ann_chunks.extend(term)\n",
    "    \n",
    "    return ann_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_input(snippet_id, rel_tup, chunks):\n",
    "    \"\"\"Helper function that creates one input snippet for BERT SRE\n",
    "    \n",
    "    Inputs:\n",
    "    snippet_id = filename of snippet\n",
    "    rel_tup = tuple from relations list generated by process_ann()\n",
    "          format: (relation ID, relation_type, entity ID #1, entity ID #2)\n",
    "    chunks = list of annotated chunks from ann_chunker()\n",
    "    \n",
    "    Output:\n",
    "    rel_input = input snippet ready for BERT SRE\n",
    "                format: [snippet_id+relation_id]/t[relation_type]/t[cleaned snippet with ner markers]\"\"\"\n",
    "    \n",
    "    # unpack relation_tup\n",
    "    relation_id = rel_tup[0]\n",
    "    relation_type = rel_tup[1]\n",
    "    entity_list = [rel_tup[2], rel_tup[3]]\n",
    "    \n",
    "    new_id = snippet_id + '-' + relation_id\n",
    "    \n",
    "    # build cleaned snippet with ner markers\n",
    "    snippets = []\n",
    "    i = 1\n",
    "    \n",
    "    for tup in chunks:\n",
    "        chunk, label, entity = tup\n",
    "        \n",
    "        # clean chunk: remove punctuation,\n",
    "        # word tokenize if not an entity\n",
    "        # split by whitespace if entity\n",
    "        processed_chunk = []\n",
    "            \n",
    "        if label == 'O':\n",
    "            nopunct = re.sub(r'[,/()\":\\-\\[\\]\\']', '', chunk.strip())\n",
    "            sentences = sent_tokenize(nopunct)\n",
    "            if sentences:\n",
    "                for s in sentences:\n",
    "                    for x in word_tokenize(s):\n",
    "                        processed_chunk.append(x)\n",
    "                \n",
    "        else:\n",
    "            nopunct = re.sub(r'[,/()\":\\-\\[\\]\\']', '', chunk)\n",
    "            tokens = [x for x in nopunct.split(' ') if x]\n",
    "            for t in tokens:\n",
    "                processed_chunk.append(t)\n",
    "        \n",
    "        # add ner markers before and after entities in relation\n",
    "        if entity in entity_list:\n",
    "            snippets.append(f'[E{i}]')\n",
    "            snippets.extend(processed_chunk)\n",
    "            snippets.append(f'[/E{i}]')\n",
    "            i += 1\n",
    "        \n",
    "        else:\n",
    "            snippets.extend(processed_chunk)\n",
    "\n",
    "    # join snippet chunks to one clean snippet\n",
    "    cleaned_snippet = ' '.join(snippets)\n",
    "    \n",
    "    return [new_id, relation_type, cleaned_snippet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_lengths = []\n",
    "\n",
    "for file in filenames_train:\n",
    "    \n",
    "    snippet_id = file[-4:]\n",
    "\n",
    "    cleaned_offsets, relations = process_ann2(f'{path_train}/{file}.ann')\n",
    "    chunks = ann_chunker(f'{path_train}/{file}.txt', cleaned_offsets)\n",
    "\n",
    "    for tup in relations:\n",
    "        line = relation_input(snippet_id, tup, chunks)\n",
    "        snippets = line[2].split(' ')\n",
    "        snippet_lengths.append(len(snippets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median snippet length in train set: 132\n",
      "Average snippet length in train set: 175.6\n",
      "Max snippet length in train set: 969\n"
     ]
    }
   ],
   "source": [
    "print(f'Median snippet length in train set: {median(snippet_lengths)}')\n",
    "print(f'Average snippet length in train set: {mean(snippet_lengths):.1f}')\n",
    "print(f'Max snippet length in train set: {max(snippet_lengths)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of snippets: 45821\n",
      "Number of snippets with length > 200: 7752\n",
      "Number of snippets with length > 250: 4378\n",
      "Number of snippets with length > 300: 3974\n",
      "Number of snippets with length > 400: 3168\n",
      "Number of snippets with length > 500: 2773\n"
     ]
    }
   ],
   "source": [
    "count = [1 for x in snippet_lengths]\n",
    "print(f'Total number of snippets: {len(count)}') \n",
    "\n",
    "count1 = [1 for x in snippet_lengths if x > 200]\n",
    "print(f'Number of snippets with length > 200: {len(count1)}')\n",
    "\n",
    "count2 = [1 for x in snippet_lengths if x > 250]\n",
    "print(f'Number of snippets with length > 250: {len(count2)}')\n",
    "\n",
    "count3 = [1 for x in snippet_lengths if x > 300]\n",
    "print(f'Number of snippets with length > 300: {len(count3)}')\n",
    "\n",
    "count4 = [1 for x in snippet_lengths if x > 400]\n",
    "print(f'Number of snippets with length > 400: {len(count4)}')\n",
    "\n",
    "count5 = [1 for x in snippet_lengths if x > 500]\n",
    "print(f'Number of snippets with length > 500: {len(count5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

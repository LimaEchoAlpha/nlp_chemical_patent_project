{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"sm_base_bert-Copy1.ipynb","provenance":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dc3b25a20e83490393ecc186cc69469d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d65d510a73b34dabb80c2ac53711d035","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_14cf3a4b78da4ea18da91d0b4cd94a4f","IPY_MODEL_96a2fcd31d844e499542525bc0e78aeb","IPY_MODEL_163b6f31cd314269aa9dd00351f5ee24"]}},"d65d510a73b34dabb80c2ac53711d035":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"14cf3a4b78da4ea18da91d0b4cd94a4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8c96ef180a2b42918d4889a246c786e5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a4ed9fac5aac447faad115e762386889"}},"96a2fcd31d844e499542525bc0e78aeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4bb99d7d946c4079ac0a1b9cc6b9c8f8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":526681800,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":526681800,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5297bbf787754cdfb2e9309c7d9b2ea8"}},"163b6f31cd314269aa9dd00351f5ee24":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6c4e8444eedf40699e991ce705dec328","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 502M/502M [00:16&lt;00:00, 27.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5030ab790a754bf4b3db74d89894838b"}},"8c96ef180a2b42918d4889a246c786e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a4ed9fac5aac447faad115e762386889":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4bb99d7d946c4079ac0a1b9cc6b9c8f8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5297bbf787754cdfb2e9309c7d9b2ea8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6c4e8444eedf40699e991ce705dec328":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5030ab790a754bf4b3db74d89894838b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"WLvnz5H4gc9c"},"source":["import json\n","import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","import tensorflow as tf\n","from time import time\n","import io\n","import re\n","\n","import pickle\n","from csv import reader\n","import matplotlib.pyplot as plt\n","\n","import matplotlib.pyplot as plt\n","from matplotlib import colors\n","from matplotlib.ticker import PercentFormatter\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras.backend import sparse_categorical_crossentropy\n","from tensorflow.keras.layers import Dense, Flatten\n","\n","from datetime import datetime\n","\n","from collections import defaultdict\n","\n","from transformers import BertTokenizer, TFBertModel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cubmwVgQgmFX"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6F1NQcXgc9f"},"source":["tf.get_logger().setLevel(\"ERROR\") "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JL4HW7_Eg8GA","executionInfo":{"status":"ok","timestamp":1636944881852,"user_tz":300,"elapsed":39313,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"2b0da9dd-9872-4df6-801f-7ddf5da719c4"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"q7ZBZjDagc9g"},"source":["# path = '../data/sample'\n","# filename = 'sample_nopunct.csv'\n","# full_path = f'{path}/{filename}'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qRzfLnXXgc9h"},"source":["full_path = 'drive/MyDrive/W266/chemical_patent_cer_ee/data/sample/sample_nopunct.csv'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZOVSFr6gc9i"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5Kt6rqygc9i","executionInfo":{"status":"ok","timestamp":1636944794639,"user_tz":300,"elapsed":92,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"6f8fef3c-2b7f-484f-d89b-7ce14afdea3d"},"source":["encoded_input = tokenizer('7Cyclopropylmethyl15isopropylisoxazol4ylmethyl3methyl1Hpurine263H7Hdione')\n","encoded_input"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 128, 1658, 1183, 1665, 13200, 12736, 7777, 11006, 18873, 16337, 1548, 4184, 12736, 7777, 1548, 10649, 10961, 4063, 1527, 7777, 11006, 18873, 1495, 11006, 18873, 1475, 3048, 4093, 2042, 25129, 1495, 3048, 1559, 3048, 13447, 1673, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Pwa7N_vgc9j","executionInfo":{"status":"ok","timestamp":1636944796683,"user_tz":300,"elapsed":76,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"76fb842e-5988-42e0-840f-eb31012a8e92"},"source":["len(encoded_input['input_ids'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["38"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vSN5P6NNgc9k","executionInfo":{"status":"ok","timestamp":1636944797957,"user_tz":300,"elapsed":70,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"fe8a16d3-1f47-4f0a-9494-086b9235abf4"},"source":["tokenizer.decode(encoded_input[\"input_ids\"])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] 7Cyclopropylmethyl15isopropylisoxazol4ylmethyl3methyl1Hpurine263H7Hdione [SEP]'"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wCVrNecEgc9k","executionInfo":{"status":"ok","timestamp":1636944799247,"user_tz":300,"elapsed":76,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"6662a908-e373-4e1c-a991-d3ddb2adb631"},"source":["tokenizer.decode(7777)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'# # y l'"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"m6YxVW3Ygc9l"},"source":["#### Generate inputs"]},{"cell_type":"code","metadata":{"id":"Ei2M5e79gc9m"},"source":["def addWord(word, ner):\n","    \"\"\"\n","    Convert a word into a word token and add supplied NER labels. \n","    Note that the word can be tokenized to two or more tokens. \n","    Correspondingly, we add - for now - custom 'X' tokens to the labels \n","    in order to maintain the 1:1 mappings between word tokens and labels.\n","    \n","    arguments: word, ner label\n","    returns: dictionary with tokens and labels\n","    \n","    *Function modified from BERT_T5_NER_2_3_030521\n","    \"\"\"\n","    \n","    tokens = tokenizer.tokenize(word)\n","    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n","    \n","    addDict = dict()\n","    \n","    addDict['wordToken'] = tokens\n","    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n","    addDict['tokenLength'] = tokenLength\n","    \n","    return addDict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bb5Bn04Vgc9n"},"source":["def generate_bert_ner_inputs(full_path, max_length=400):\n","    \"\"\"\n","    Read the file line by line and construct snippets (\"sentences\"). \n","    A snippet end is marked by 'SNIPPET: [snippet id]' in the next row.\n","    \n","    Also, cap snippet length using max_length. \n","    Snippets which are shorter than max_length are padded. \n","    All snippets end with a [SEP] token, padded or not.\n","    \n","    arguments: full path of input file, max length of snippet\n","    returns: lists for BERT inputs (bertSentenceIDs, bertMasks, bertSequenceIDs)\n","             and the inputs before BERT tokenization (sentenceList, nerTokenList, sentLengthList)\n","    \n","    *Function modified from BERT_T5_NER_2_3_030521\n","    \"\"\"\n","\n","    with io.open(full_path, 'r', encoding='utf-8', errors='ignore') as f:\n","        text = f.readlines()\n","\n","\n","    # lists for sentences, tokens, labels, etc. \n","    sentenceTokenList = []\n","    nerTokenList = []\n","    sentLengthList = []\n","\n","    # lists for BERT input\n","    bertSentenceIDs = []\n","    bertMasks = []\n","    bertSequenceIDs = []\n","\n","    # always start with [CLS] tokens\n","    sentenceTokens = ['[CLS]']\n","    nerTokens = ['[nerCLS]']\n","\n","    for line in text:\n","        \n","        parsed_line = line.strip().split('\\t')\n","        \n","        # if new sentence starts\n","        if parsed_line[0][:8] == 'SNIPPET:':\n","            \n","            if len(sentenceTokens) > 1:\n","            \n","                # figure out sentence length for padding or truncating\n","                sentenceLength = min(max_length -1, len(sentenceTokens))\n","                sentLengthList.append(sentenceLength)\n","\n","                # Create space for at least a final '[SEP]' token\n","                if sentenceLength >= max_length - 1: \n","                    sentenceTokens = sentenceTokens[:max_length - 2]\n","                    nerTokens = nerTokens[:max_length - 2]\n","\n","                # add a ['SEP'] token and padding \n","                sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n","                nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n","\n","                # append current data to lists\n","                sentenceTokenList.append(sentenceTokens)\n","                nerTokenList.append(nerTokens)\n","\n","                # generate BERT tokens\n","                bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n","                #bertSentenceIDs.append(tokenizer.prepare_seq2seq_batch(sentenceTokens, return_tensors='tf'))\n","                bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n","                bertSequenceIDs.append([0] * (max_length))\n","\n","                # initialize new sentence\n","                sentenceTokens = ['[CLS]']\n","                nerTokens = ['[nerCLS]']\n","                \n","        elif parsed_line[0]:\n","            word = parsed_line[0]\n","            ner = parsed_line[1]\n","            \n","            addDict = addWord(word, ner)\n","            sentenceTokens += addDict['wordToken']\n","            nerTokens += addDict['nerToken']\n","    \n","    # take care of last sentence\n","    # figure out sentence length for padding or truncating\n","    sentenceLength = min(max_length -1, len(sentenceTokens))\n","    sentLengthList.append(sentenceLength)\n","\n","    # Create space for at least a final '[SEP]' token\n","    if sentenceLength >= max_length - 1: \n","        sentenceTokens = sentenceTokens[:max_length - 2]\n","        nerTokens = nerTokens[:max_length - 2]\n","\n","    # add a ['SEP'] token and padding \n","    sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n","    nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n","\n","    # append current data to lists\n","    sentenceTokenList.append(sentenceTokens)\n","    nerTokenList.append(nerTokens)\n","\n","    # generate BERT tokens\n","    bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n","    bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n","    bertSequenceIDs.append([0] * (max_length))\n","\n","    return sentenceTokenList, nerTokenList, sentLengthList, bertSentenceIDs, bertMasks, bertSequenceIDs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twYlaBEsgc9o"},"source":["with io.open(full_path, 'r', encoding='utf-8', errors='ignore') as f:\n","    text = f.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1ALX_qXFgc9p","executionInfo":{"status":"ok","timestamp":1636945012429,"user_tz":300,"elapsed":102,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"7437cc1a-5409-4c2d-f8b3-d971f176833d"},"source":["text[:10]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['SNIPPET: 0049\\n',\n"," 'Example\\tO\\n',\n"," '58\\tB-EXAMPLE_LABEL\\n',\n"," '7Cyclopropylmethyl15isopropylisoxazol4ylmethyl3methyl1Hpurine263H7Hdione\\tB-REACTION_PRODUCT\\n',\n"," 'Step\\tO\\n',\n"," '1\\tB-EXAMPLE_LABEL\\n',\n"," '7Cyclopropylmethyl15isopropylisoxazol4ylmethyl3methyl1Hpurine263H7Hdione\\tB-REACTION_PRODUCT\\n',\n"," '4Chloromethyl5isopropylisoxazole\\tB-STARTING_MATERIAL\\n',\n"," '100\\tO\\n',\n"," 'mg\\tO\\n']"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"GQHi7ysMgc9p","executionInfo":{"status":"ok","timestamp":1636945014825,"user_tz":300,"elapsed":118,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"22ef026a-742f-4b03-95a2-71e5509fe0e5"},"source":["parsed_line = text[3].strip().split('\\t')\n","parsed_line[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'7Cyclopropylmethyl15isopropylisoxazol4ylmethyl3methyl1Hpurine263H7Hdione'"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"ay3NVDEKgc9q"},"source":["sentenceTokenList, nerTokenList, sentLengthList, bertSentenceIDs, bertMasks, bertSequenceIDs = generate_bert_ner_inputs(full_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Izhuvwdvgc9q","executionInfo":{"status":"ok","timestamp":1636945017848,"user_tz":300,"elapsed":100,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"0fa30f1a-f821-4404-883a-b15c3a233936"},"source":["# sanity check\n","len(nerTokenList)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"clcP35Ojgc9q"},"source":["#### Initial Data Analysis"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"a58GsyvXgc9q","executionInfo":{"status":"ok","timestamp":1636945022092,"user_tz":300,"elapsed":492,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"6ec2a8fd-5faa-48f0-ae44-1d577c12ee61"},"source":["max_length = 400\n","sentenceLengths= [l for l in sentLengthList]\n","plt.hist(np.array(sentenceLengths), bins=(50))\n","pass"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARBUlEQVR4nO3df4xlZX3H8ffHZQUTiFSZ6GbZdbCQNmoUcIoYm4ZgSPlh2DZisiZVMJhNrERMbFqwCSpJE2hSaRQi2QoF1AgWjV0FYmjBqH+wOOCyAit1VBogVBYQkKjYtd/+MWf19nLv3Du7d349fb+Skz3nOc/c833mXD6cOffcc1JVSJLWvpesdAGSpMkw0CWpEQa6JDXCQJekRhjoktSIQ1Zqw0cddVRNT0+v1OYlaU265557nqyqqUHrVizQp6enmZ2dXanNS9KalOQ/h63zlIskNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqxNiBnmRdku8l+fqAdYcmuSnJXJKdSaYnWaQkabTFHKFfCOwZsu584GdVdSxwBXD5wRYmSVqcsQI9ydHAWcBnh3TZAlzfzd8MvD1JDr48SdK4xv2m6D8Cfw0cMWT9RuARgKral+RZ4JXAk72dkmwDtgFs3rz5QOrVGjZ90S0D2x++7KxlruT/L/dB20YeoSd5B/BEVd1zsBurqu1VNVNVM1NTA29FIEk6QOOccnkbcHaSh4EbgVOTfL6vz2PAJoAkhwAvB56aYJ2SpBFGBnpVXVxVR1fVNLAVuKOq/qKv2w7g3G7+nK6PDyuVpGV0wHdbTHIpMFtVO4BrgM8lmQOeZj74JUnLaFGBXlXfBL7ZzV/S0/4r4F2TLEyStDh+U1SSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1IhxHhJ9WJK7k9yX5IEknxjQ57wke5Ps6qb3L025kqRhxnli0QvAqVX1fJL1wHeS3FZVd/X1u6mqLph8iZKkcYwM9O5hz893i+u7yQdAS9IqM9Y59CTrkuwCngBur6qdA7q9M8nuJDcn2TTRKiVJI40V6FX1m6o6HjgaOCnJG/q6fA2Yrqo3ArcD1w96nSTbkswmmd27d+/B1C1J6rOoq1yq6hngTuD0vvanquqFbvGzwJuH/Pz2qpqpqpmpqakDqVeSNMQ4V7lMJTmym38ZcBrwg74+G3oWzwb2TLJISdJo41zlsgG4Psk65v8H8KWq+nqSS4HZqtoBfCjJ2cA+4GngvKUqWJI02DhXuewGThjQfknP/MXAxZMtTZK0GH5TVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxzjNFD0tyd5L7kjyQ5BMD+hya5KYkc0l2JpleimIlScONc4T+AnBqVb0JOB44PcnJfX3OB35WVccCVwCXT7ZMSdIoIwO95j3fLa7vpurrtgW4vpu/GXh7kkysSknSSCMfEg2QZB1wD3AscFVV7ezrshF4BKCq9iV5Fngl8GTf62wDtgFs3rz54CpX86YvumVg+8OXnTWR/stRk7ScxvpQtKp+U1XHA0cDJyV5w4FsrKq2V9VMVc1MTU0dyEtIkoZY1FUuVfUMcCdwet+qx4BNAEkOAV4OPDWJAiVJ4xnnKpepJEd28y8DTgN+0NdtB3BuN38OcEdV9Z9nlyQtoXHOoW8Aru/Oo78E+FJVfT3JpcBsVe0ArgE+l2QOeBrYumQVS5IGGhnoVbUbOGFA+yU9878C3jXZ0iRJi+E3RSWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakR4zxTdFOSO5M8mOSBJBcO6HNKkmeT7OqmSwa9liRp6YzzTNF9wEeq6t4kRwD3JLm9qh7s6/ftqnrH5EuUJI1j5BF6VT1eVfd28z8H9gAbl7owSdLiLOocepJp5h8YvXPA6rcmuS/JbUleP+TntyWZTTK7d+/eRRcrSRpu7EBPcjjwZeDDVfVc3+p7gddU1ZuATwNfHfQaVbW9qmaqamZqaupAa5YkDTBWoCdZz3yYf6GqvtK/vqqeq6rnu/lbgfVJjppopZKkBY1zlUuAa4A9VfXJIX1e3fUjyUnd6z41yUIlSQsb5yqXtwHvAb6fZFfX9lFgM0BVXQ2cA3wgyT7gl8DWqqolqFeSNMTIQK+q7wAZ0edK4MpJFSVJWjy/KSpJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNGOeZopuS3JnkwSQPJLlwQJ8k+VSSuSS7k5y4NOVKkoYZ55mi+4CPVNW9SY4A7klye1U92NPnDOC4bnoL8JnuX0nSMhl5hF5Vj1fVvd38z4E9wMa+bluAG2reXcCRSTZMvFpJ0lDjHKH/VpJp4ARgZ9+qjcAjPcuPdm2P9/38NmAbwObNmxdX6ZimL7plYPvDl521JNtbrYb9HmD472Khn1mMpf5dL7bOA/ldLNak3neLfR3f7+o19oeiSQ4Hvgx8uKqeO5CNVdX2qpqpqpmpqakDeQlJ0hBjBXqS9cyH+Req6isDujwGbOpZPrprkyQtk3GucglwDbCnqj45pNsO4L3d1S4nA89W1eND+kqSlsA459DfBrwH+H6SXV3bR4HNAFV1NXArcCYwB/wCeN/kS5UkLWRkoFfVd4CM6FPABydVlCRp8fymqCQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDVinGeKXpvkiST3D1l/SpJnk+zqpksmX6YkaZRxnil6HXAlcMMCfb5dVe+YSEWSpAMy8gi9qr4FPL0MtUiSDsKkzqG/Ncl9SW5L8vphnZJsSzKbZHbv3r0T2rQkCSYT6PcCr6mqNwGfBr46rGNVba+qmaqamZqamsCmJUn7HXSgV9VzVfV8N38rsD7JUQddmSRpUQ460JO8Okm6+ZO613zqYF9XkrQ4I69ySfJF4BTgqCSPAh8D1gNU1dXAOcAHkuwDfglsrapasoolSQONDPSqeveI9Vcyf1mjJGkF+U1RSWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJasTIQE9ybZInktw/ZH2SfCrJXJLdSU6cfJmSpFHGOUK/Djh9gfVnAMd10zbgMwdfliRpsUYGelV9C3h6gS5bgBtq3l3AkUk2TKpASdJ4Rj4kegwbgUd6lh/t2h7v75hkG/NH8WzevPmANzh90S0T+5mHLztrIv0ntd0WLHb/HMj+nJSV2vZSb3eS+2Cp/xtp2XL/jpb1Q9Gq2l5VM1U1MzU1tZyblqTmTSLQHwM29Swf3bVJkpbRJAJ9B/De7mqXk4Fnq+pFp1skSUtr5Dn0JF8ETgGOSvIo8DFgPUBVXQ3cCpwJzAG/AN63VMVKkoYbGehV9e4R6wv44MQqkiQdEL8pKkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0YK9CTnJ7koSRzSS4asP68JHuT7Oqm90++VEnSQsZ5pug64CrgNOBR4LtJdlTVg31db6qqC5agRknSGMY5Qj8JmKuqH1fVr4EbgS1LW5YkabHGCfSNwCM9y492bf3emWR3kpuTbBr0Qkm2JZlNMrt3794DKFeSNMykPhT9GjBdVW8EbgeuH9SpqrZX1UxVzUxNTU1o05IkGC/QHwN6j7iP7tp+q6qeqqoXusXPAm+eTHmSpHGNE+jfBY5LckySlwJbgR29HZJs6Fk8G9gzuRIlSeMYeZVLVe1LcgHwDWAdcG1VPZDkUmC2qnYAH0pyNrAPeBo4bwlrliQNMDLQAarqVuDWvrZLeuYvBi6ebGmSpMXwm6KS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiLECPcnpSR5KMpfkogHrD01yU7d+Z5LpSRcqSVrYyEBPsg64CjgDeB3w7iSv6+t2PvCzqjoWuAK4fNKFSpIWNs4R+knAXFX9uKp+DdwIbOnrswW4vpu/GXh7kkyuTEnSKKmqhTsk5wCnV9X7u+X3AG+pqgt6+tzf9Xm0W/5R1+fJvtfaBmzrFv8AeGhSA1lGRwFPjuy1+jmO1cVxrD6rdSyvqaqpQSsOWc4qqmo7sH05tzlpSWaramal6zhYjmN1cRyrz1ocyzinXB4DNvUsH921DeyT5BDg5cBTkyhQkjSecQL9u8BxSY5J8lJgK7Cjr88O4Nxu/hzgjhp1LkeSNFEjT7lU1b4kFwDfANYB11bVA0kuBWaragdwDfC5JHPA08yHfqvW9CmjHo5jdXEcq8+aG8vID0UlSWuD3xSVpEYY6JLUCAO9R5JrkzzRXVe/v+0VSW5P8sPu39/r2pPkU93tDnYnOXHlKv+/hozj40keS7Krm87sWXdxN46HkvzpylT9Ykk2JbkzyYNJHkhyYde+pvbJAuNYi/vksCR3J7mvG8snuvZjutt+zHW3AXlp174qbwuywDiuS/KTnn1yfNe+Kt9bL1JVTt0E/AlwInB/T9vfAxd18xcBl3fzZwK3AQFOBnaudP0jxvFx4K8G9H0dcB9wKHAM8CNg3UqPoattA3BiN38E8B9dvWtqnywwjrW4TwIc3s2vB3Z2v+svAVu79quBD3Tzfwlc3c1vBW5a6TGMGMd1wDkD+q/K91b/5BF6j6r6FvNX6fTqva3B9cCf9bTfUPPuAo5MsmF5Kl3YkHEMswW4sapeqKqfAHPM3+5hxVXV41V1bzf/c2APsJE1tk8WGMcwq3mfVFU93y2u76YCTmX+th/w4n2y6m4LssA4hlmV761+Bvpor6qqx7v5/wJe1c1vBB7p6fcoC/9Huhpc0P25eO3+0xSskXF0f6qfwPyR1JrdJ33jgDW4T5KsS7ILeAK4nfm/IJ6pqn1dl956fzuWbv2zwCuXt+LB+sdRVfv3yd91++SKJId2bat6n+xnoC9Czf/ttVav8/wM8PvA8cDjwD+sbDnjS3I48GXgw1X1XO+6tbRPBoxjTe6TqvpNVR3P/LfGTwL+cIVLOiD940jyBuBi5sfzR8ArgL9ZwRIXzUAf7af7/7Tq/n2iax/nlgirRlX9tHsD/w/wT/zuT/hVPY4k65kPwS9U1Ve65jW3TwaNY63uk/2q6hngTuCtzJ+C2P9Fxd56V/1tQXrGcXp3eqyq6gXgn1lj+8RAH633tgbnAv/a0/7e7tPvk4Fne04DrDp95/v+HNh/BcwOYGt3NcIxwHHA3ctd3yDdudZrgD1V9cmeVWtqnwwbxxrdJ1NJjuzmXwacxvxnAncyf9sPePE+WXW3BRkyjh/0HCiE+c8BevfJqntvvchKfyq7mibgi8z/6fvfzJ8jO5/5833/DvwQ+DfgFfW7T8mvYv784feBmZWuf8Q4PtfVuZv5N+eGnv5/243jIeCMla6/p64/Zv50ym5gVzedudb2yQLjWIv75I3A97qa7wcu6dpfy/z/dOaAfwEO7doP65bnuvWvXekxjBjHHd0+uR/4PL+7EmZVvrf6J7/6L0mN8JSLJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmN+F9oyCFzBzxtSgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vlJAefdQgc9r","executionInfo":{"status":"ok","timestamp":1636945022770,"user_tz":300,"elapsed":126,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"c7b012fa-3046-4d57-c080-e25cb61a7657"},"source":["len(sentLengthList)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["50"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"DPtSgaSFgc9r"},"source":["numSentences = len(bertSentenceIDs)\n","\n","nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n","nerClasses.columns = ['tag']\n","nerClasses.tag = pd.Categorical(nerClasses.tag)\n","nerClasses['cat'] = nerClasses.tag.cat.codes\n","nerClasses['sym'] = nerClasses.tag.cat.codes\n","nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"FYVykgT_gc9s","executionInfo":{"status":"ok","timestamp":1636945026351,"user_tz":300,"elapsed":876,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"21877533-5e24-4fd2-88b8-83d2b8d2c2ad"},"source":["nerClasses[['cat']].hist(bins=21)\n","pass"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"zOTLjDgXgc9s","executionInfo":{"status":"ok","timestamp":1636945027499,"user_tz":300,"elapsed":106,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"21e30609-4ec5-4fd9-d6a4-9ddec6959649"},"source":["nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n","                   .rename(columns={'sym':'occurences'}))\n","\n","numNerClasses = nerDistribution.tag.nunique()\n","\n","nerDistribution"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tag</th>\n","      <th>cat</th>\n","      <th>occurences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>B-EXAMPLE_LABEL</td>\n","      <td>0</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>B-EXAMPLE_LABEL</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>B-EXAMPLE_LABEL</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>B-EXAMPLE_LABEL</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>B-EXAMPLE_LABEL</td>\n","      <td>4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>671</th>\n","      <td>nerX</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>672</th>\n","      <td>nerX</td>\n","      <td>22</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>673</th>\n","      <td>nerX</td>\n","      <td>23</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>674</th>\n","      <td>nerX</td>\n","      <td>24</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>675</th>\n","      <td>nerX</td>\n","      <td>25</td>\n","      <td>5226</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>676 rows × 3 columns</p>\n","</div>"],"text/plain":["                 tag  cat  occurences\n","0    B-EXAMPLE_LABEL    0          49\n","1    B-EXAMPLE_LABEL    1           0\n","2    B-EXAMPLE_LABEL    2           0\n","3    B-EXAMPLE_LABEL    3           0\n","4    B-EXAMPLE_LABEL    4           0\n","..               ...  ...         ...\n","671             nerX   21           0\n","672             nerX   22           0\n","673             nerX   23           0\n","674             nerX   24           0\n","675             nerX   25        5226\n","\n","[676 rows x 3 columns]"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":824},"id":"nCGzF-rSgc9s","executionInfo":{"status":"ok","timestamp":1636945029011,"user_tz":300,"elapsed":122,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"b1a9b931-09a7-4a48-e0e7-0f5ae4ad698a"},"source":["ner_categories = nerDistribution.loc[(nerDistribution.iloc[:,1:]!=0).all(1)].reset_index()\n","ner_categories"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>tag</th>\n","      <th>cat</th>\n","      <th>occurences</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>27</td>\n","      <td>B-OTHER_COMPOUND</td>\n","      <td>1</td>\n","      <td>176</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>54</td>\n","      <td>B-REACTION_PRODUCT</td>\n","      <td>2</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>81</td>\n","      <td>B-REACTION_STEP</td>\n","      <td>3</td>\n","      <td>172</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>108</td>\n","      <td>B-REAGENT_CATALYST</td>\n","      <td>4</td>\n","      <td>58</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>135</td>\n","      <td>B-SOLVENT</td>\n","      <td>5</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>162</td>\n","      <td>B-STARTING_MATERIAL</td>\n","      <td>6</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>189</td>\n","      <td>B-TEMPERATURE</td>\n","      <td>7</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>216</td>\n","      <td>B-TIME</td>\n","      <td>8</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>243</td>\n","      <td>B-WORKUP</td>\n","      <td>9</td>\n","      <td>120</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>270</td>\n","      <td>B-YIELD_OTHER</td>\n","      <td>10</td>\n","      <td>57</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>297</td>\n","      <td>B-YIELD_PERCENT</td>\n","      <td>11</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>324</td>\n","      <td>I-OTHER_COMPOUND</td>\n","      <td>12</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>351</td>\n","      <td>I-REACTION_PRODUCT</td>\n","      <td>13</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>378</td>\n","      <td>I-REAGENT_CATALYST</td>\n","      <td>14</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>405</td>\n","      <td>I-SOLVENT</td>\n","      <td>15</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>432</td>\n","      <td>I-STARTING_MATERIAL</td>\n","      <td>16</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>459</td>\n","      <td>I-TEMPERATURE</td>\n","      <td>17</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>486</td>\n","      <td>I-TIME</td>\n","      <td>18</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>513</td>\n","      <td>I-YIELD_OTHER</td>\n","      <td>19</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>540</td>\n","      <td>I-YIELD_PERCENT</td>\n","      <td>20</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>567</td>\n","      <td>O</td>\n","      <td>21</td>\n","      <td>3480</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>594</td>\n","      <td>[nerCLS]</td>\n","      <td>22</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>621</td>\n","      <td>[nerPAD]</td>\n","      <td>23</td>\n","      <td>9781</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>648</td>\n","      <td>[nerSEP]</td>\n","      <td>24</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>675</td>\n","      <td>nerX</td>\n","      <td>25</td>\n","      <td>5226</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    index                  tag  cat  occurences\n","0      27     B-OTHER_COMPOUND    1         176\n","1      54   B-REACTION_PRODUCT    2         110\n","2      81      B-REACTION_STEP    3         172\n","3     108   B-REAGENT_CATALYST    4          58\n","4     135            B-SOLVENT    5          61\n","5     162  B-STARTING_MATERIAL    6          88\n","6     189        B-TEMPERATURE    7          74\n","7     216               B-TIME    8          47\n","8     243             B-WORKUP    9         120\n","9     270        B-YIELD_OTHER   10          57\n","10    297      B-YIELD_PERCENT   11          50\n","11    324     I-OTHER_COMPOUND   12          56\n","12    351   I-REACTION_PRODUCT   13          56\n","13    378   I-REAGENT_CATALYST   14          38\n","14    405            I-SOLVENT   15           3\n","15    432  I-STARTING_MATERIAL   16          40\n","16    459        I-TEMPERATURE   17          55\n","17    486               I-TIME   18          46\n","18    513        I-YIELD_OTHER   19          56\n","19    540      I-YIELD_PERCENT   20           1\n","20    567                    O   21        3480\n","21    594             [nerCLS]   22          50\n","22    621             [nerPAD]   23        9781\n","23    648             [nerSEP]   24          50\n","24    675                 nerX   25        5226"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"LEs7QkQKgc9s"},"source":["#### Baseline: Always picking 'Other'"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"09XW0kVCgc9s","executionInfo":{"status":"ok","timestamp":1636945031571,"user_tz":300,"elapsed":109,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"cb12b5cf-a9dc-49d1-9fbd-899fafff9534"},"source":["O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n","                                .reset_index().drop(['index'], axis=1).loc[21])   # Some gymnasics to get the count..\n","All_occurences = nerDistribution[nerDistribution.cat < 22]['occurences'].sum()\n","\n","O_occurences/All_occurences"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.7112201103617413"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"Q_w5w3IFgc9t"},"source":["#### Train/Test Split"]},{"cell_type":"code","metadata":{"id":"MV2FTuYmgc9t"},"source":["bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kGg82GcGgc9t"},"source":["numSentences = len(bert_inputs[0])\n","np.random.seed(0)\n","training_examples = np.random.binomial(1, 0.7, numSentences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ca16nansgc9t"},"source":["trainSentence_ids = []\n","trainMasks = []\n","trainSequence_ids = []\n","\n","testSentence_ids = []\n","testMasks = []\n","testSequence_ids = []\n","\n","nerLabels_train =[]\n","nerLabels_test = []\n","\n","\n","for example in range(numSentences):\n","    if training_examples[example] == 1:\n","        trainSentence_ids.append(bert_inputs[0][example])\n","        trainMasks.append(bert_inputs[1][example])\n","        trainSequence_ids.append(bert_inputs[2][example])\n","        nerLabels_train.append(nerLabels[example])\n","    else:\n","        testSentence_ids.append(bert_inputs[0][example])\n","        testMasks.append(bert_inputs[1][example])\n","        testSequence_ids.append(bert_inputs[2][example])\n","        nerLabels_test.append(nerLabels[example])\n","        \n","X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n","X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n","\n","nerLabels_train = np.array(nerLabels_train)\n","nerLabels_test = np.array(nerLabels_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G5bj4DDgc9t"},"source":["# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n","\n","k_start = 0\n","k_end = -1\n","\n","if k_end == -1:\n","    k_end_train = X_train[0].shape[0]\n","    k_end_test = X_test[0].shape[0]\n","else:\n","    k_end_train = k_end_test = k_end\n","    \n","\n","\n","bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n","                       X_train[2][k_start:k_end_train]]\n","bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n","                      X_test[2][k_start:k_end_test]]\n","\n","\n","labels_train_k = nerLabels_train[k_start:k_end_train]\n","labels_test_k = nerLabels_test[k_start:k_end_test]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CDUfC1_Ggc9t"},"source":["## The Model"]},{"cell_type":"markdown","metadata":{"id":"3O6Uf0Srgc9t"},"source":["#### Custom Loss & Accuracy\n","(from BERT_T5_NER_2_3_030521)"]},{"cell_type":"markdown","metadata":{"id":"yFvnPGmegc9u"},"source":["We need a custom loss function because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit: we want to mask out all tokens that have a token id larger or equal to 22, corresponding to the extra tokens:"]},{"cell_type":"code","metadata":{"id":"FPViYJ8Ngc9u"},"source":["def custom_loss(y_true, y_pred):\n","    \"\"\"\n","    calculate loss function explicitly, filtering out 'extra inserted labels'\n","    \n","    y_true: Shape: (batch x (max_length + 1) )\n","    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n","    \n","    returns:  cost\n","    \"\"\"\n","\n","    #get labels and predictions\n","    \n","    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n","    \n","    mask = (y_label < 22)   # This mask is used to remove all tokens that do not correspond to the original base text.\n","\n","    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n","    \n","    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n","    \n","    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n","    \n","    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TJzBYETvgc9u"},"source":["def custom_acc_orig_tokens(y_true, y_pred):\n","    \"\"\"\n","    calculate loss dfunction filtering out also the newly inserted labels\n","    \n","    y_true: Shape: (batch x (max_length) )\n","    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n","    \n","    returns: accuracy\n","    \"\"\"\n","\n","    #get labels and predictions\n","    \n","    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n","    \n","    mask = (y_label < 22)\n","    y_label_masked = tf.boolean_mask(y_label, mask)\n","    \n","    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n","                                                    [-1, numNerClasses]), axis=1)\n","    \n","    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n","\n","    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l-2UhsNcgc9u"},"source":["def custom_acc_orig_non_other_tokens(y_true, y_pred):\n","    \"\"\"\n","    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n","    \n","    y_true: Shape: (batch x (max_length) )\n","    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n","    \n","    returns: accuracy\n","    \"\"\"\n","\n","    #get labels and predictions\n","    \n","    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n","    \n","    mask = (y_label < 21)\n","    y_label_masked = tf.boolean_mask(y_label, mask)\n","    \n","    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n","                                                    [-1, numNerClasses]), axis=1)\n","    \n","    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n","\n","    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RNCGgUPDgc9v"},"source":["#### Define Adam optimizer"]},{"cell_type":"code","metadata":{"id":"4H_GD_44gc9v"},"source":["adam_customized = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nc4C8LSXgc9v"},"source":["#### Model Construction"]},{"cell_type":"code","metadata":{"id":"pceUvWGggc9v"},"source":["def ner_model(max_input_length, train_layers, optimizer):\n","    \"\"\"\n","    Implementation of NER model\n","    \n","    variables:\n","        max_input_length: number of tokens (max_length + 1)\n","        train_layers: number of layers to be retrained\n","        optimizer: optimizer to be used\n","    \n","    returns: model\n","    \"\"\"\n","    \n","    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n","    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n","    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n","    \n","    \n","    bert_inputs = [in_id, in_mask, in_segment]\n","    \n","    \n","    \n","    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n","    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n","    \n","    bert_layer = TFBertModel.from_pretrained('bert-base-cased')\n","    \n","    # Freeze layers, i.e. only train number of layers specified, starting from the top\n","    \n","    if not train_layers == -1:\n","        \n","        retrain_layers = []\n","    \n","        for retrain_layer_number in range(train_layers):\n","\n","            layer_code = '_' + str(11 - retrain_layer_number)\n","            retrain_layers.append(layer_code)\n","\n","        for w in bert_layer.weights:\n","            if not any([x in w.name for x in retrain_layers]):\n","                w._trainable = False\n","\n","        # End of freezing section\n","    \n","    bert_sequence = bert_layer(bert_inputs)[0]\n","    \n","    print('Let us check the shape of the BERT layer output:', bert_sequence)\n","    \n","    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n","    \n","    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n","    \n","    pred = tf.keras.layers.Dense(26, activation='softmax', name='ner')(dense)\n","     \n","    print('pred: ', pred)\n","    \n","    ## Prepare for multipe loss functions, although not used here\n","    \n","    losses = {\n","        \"ner\": custom_loss,\n","        }\n","    lossWeights = {\"ner\": 1.0\n","                  }\n","    \n","    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n","\n","    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n","                                                          custom_acc_orig_non_other_tokens])\n","    \n","    \n","    model.summary()\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RL7t96EHgc9v"},"source":["#### Training BERT"]},{"cell_type":"code","metadata":{"id":"k_zf0L9vgc9w"},"source":["tf.keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["dc3b25a20e83490393ecc186cc69469d","d65d510a73b34dabb80c2ac53711d035","14cf3a4b78da4ea18da91d0b4cd94a4f","96a2fcd31d844e499542525bc0e78aeb","163b6f31cd314269aa9dd00351f5ee24","8c96ef180a2b42918d4889a246c786e5","a4ed9fac5aac447faad115e762386889","4bb99d7d946c4079ac0a1b9cc6b9c8f8","5297bbf787754cdfb2e9309c7d9b2ea8","6c4e8444eedf40699e991ce705dec328","5030ab790a754bf4b3db74d89894838b"]},"id":"iXl81Vb2gc9w","executionInfo":{"status":"ok","timestamp":1636945135050,"user_tz":300,"elapsed":82045,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"b1f15871-e279-4233-c643-6e7ced528dd2"},"source":["model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n","\n","# no layer retraining\n","\n","model.fit(\n","    bert_inputs_train_k, \n","    {\"ner\": labels_train_k },\n","    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n","    epochs=8,\n","    batch_size=32\n",")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc3b25a20e83490393ecc186cc69469d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/502M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 400, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n","pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 400, 26), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 400)]        0           []                               \n","                                                                                                  \n"," input_masks (InputLayer)       [(None, 400)]        0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 400)]        0           []                               \n","                                                                                                  \n"," tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'input_masks[0][0]',            \n","                                tentions(last_hidde               'segment_ids[0][0]']            \n","                                n_state=(None, 400,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dense (Dense)                  (None, 400, 256)     196864      ['tf_bert_model[0][0]']          \n","                                                                                                  \n"," dropout_37 (Dropout)           (None, 400, 256)     0           ['dense[0][0]']                  \n","                                                                                                  \n"," ner (Dense)                    (None, 400, 26)      6682        ['dropout_37[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,513,818\n","Trainable params: 108,513,818\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/8\n","2/2 [==============================] - 14s 5s/step - loss: 3.3398 - custom_acc_orig_tokens: 0.2665 - custom_acc_orig_non_other_tokens: 0.0224 - val_loss: 1.6480 - val_custom_acc_orig_tokens: 0.7144 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n","Epoch 2/8\n","2/2 [==============================] - 3s 1s/step - loss: 1.7360 - custom_acc_orig_tokens: 0.6976 - custom_acc_orig_non_other_tokens: 5.7670e-04 - val_loss: 1.4589 - val_custom_acc_orig_tokens: 0.7241 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n","Epoch 3/8\n","2/2 [==============================] - 3s 1s/step - loss: 1.5400 - custom_acc_orig_tokens: 0.7102 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.4638 - val_custom_acc_orig_tokens: 0.7241 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n","Epoch 4/8\n","2/2 [==============================] - 3s 1s/step - loss: 1.5322 - custom_acc_orig_tokens: 0.6973 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.2879 - val_custom_acc_orig_tokens: 0.7241 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n","Epoch 5/8\n","2/2 [==============================] - 3s 1s/step - loss: 1.3670 - custom_acc_orig_tokens: 0.7076 - custom_acc_orig_non_other_tokens: 0.0011 - val_loss: 1.0608 - val_custom_acc_orig_tokens: 0.7267 - val_custom_acc_orig_non_other_tokens: 0.0094\n","Epoch 6/8\n","2/2 [==============================] - 3s 1s/step - loss: 1.1311 - custom_acc_orig_tokens: 0.7063 - custom_acc_orig_non_other_tokens: 0.0294 - val_loss: 0.9068 - val_custom_acc_orig_tokens: 0.7541 - val_custom_acc_orig_non_other_tokens: 0.1156\n","Epoch 7/8\n","2/2 [==============================] - 3s 1s/step - loss: 0.9897 - custom_acc_orig_tokens: 0.7539 - custom_acc_orig_non_other_tokens: 0.1636 - val_loss: 0.8546 - val_custom_acc_orig_tokens: 0.7781 - val_custom_acc_orig_non_other_tokens: 0.2476\n","Epoch 8/8\n","2/2 [==============================] - 3s 1s/step - loss: 0.9267 - custom_acc_orig_tokens: 0.7490 - custom_acc_orig_non_other_tokens: 0.1835 - val_loss: 0.8354 - val_custom_acc_orig_tokens: 0.7938 - val_custom_acc_orig_non_other_tokens: 0.3656\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f10c05fd650>"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"OvQ-d1sdgc9w"},"source":["tf.keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sLvv0Ai4gc9w","executionInfo":{"status":"ok","timestamp":1636945520884,"user_tz":300,"elapsed":56707,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgzyTYobr3WBfcW_CbeVl1vthXNBKocBj7_WOpm=s64","userId":"08012892845319420981"}},"outputId":"69c09ed3-b049-4ca1-cc4a-4c857225d9b0"},"source":["tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","# retrain all layers\n","model = ner_model(max_length + 1, train_layers=5, optimizer = adam_customized)\n","\n","model.fit(\n","    bert_inputs_train_k, \n","    {\"ner\": labels_train_k },\n","    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k }),\n","    epochs=5,\n","    batch_size=16\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 400, 768), dtype=tf.float32, name=None), name='tf_bert_model_2/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model_2'\")\n","pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 400, 26), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_ids (InputLayer)         [(None, 400)]        0           []                               \n","                                                                                                  \n"," input_masks (InputLayer)       [(None, 400)]        0           []                               \n","                                                                                                  \n"," segment_ids (InputLayer)       [(None, 400)]        0           []                               \n","                                                                                                  \n"," tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n","                                thPoolingAndCrossAt               'input_masks[0][0]',            \n","                                tentions(last_hidde               'segment_ids[0][0]']            \n","                                n_state=(None, 400,                                               \n","                                 768),                                                            \n","                                 pooler_output=(Non                                               \n","                                e, 768),                                                          \n","                                 past_key_values=No                                               \n","                                ne, hidden_states=N                                               \n","                                one, attentions=Non                                               \n","                                e, cross_attentions                                               \n","                                =None)                                                            \n","                                                                                                  \n"," dense (Dense)                  (None, 400, 256)     196864      ['tf_bert_model_2[0][0]']        \n","                                                                                                  \n"," dropout_113 (Dropout)          (None, 400, 256)     0           ['dense[0][0]']                  \n","                                                                                                  \n"," ner (Dense)                    (None, 400, 26)      6682        ['dropout_113[0][0]']            \n","                                                                                                  \n","==================================================================================================\n","Total params: 108,513,818\n","Trainable params: 108,513,818\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","3/3 [==============================] - 20s 3s/step - loss: 2.4649 - custom_acc_orig_tokens: 0.4749 - custom_acc_orig_non_other_tokens: 0.0101 - val_loss: 1.4686 - val_custom_acc_orig_tokens: 0.7241 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n","Epoch 2/5\n","3/3 [==============================] - 4s 1s/step - loss: 1.4393 - custom_acc_orig_tokens: 0.7076 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.1204 - val_custom_acc_orig_tokens: 0.7248 - val_custom_acc_orig_non_other_tokens: 0.0024\n","Epoch 3/5\n","3/3 [==============================] - 4s 1s/step - loss: 1.1418 - custom_acc_orig_tokens: 0.7277 - custom_acc_orig_non_other_tokens: 0.0579 - val_loss: 0.7862 - val_custom_acc_orig_tokens: 0.7755 - val_custom_acc_orig_non_other_tokens: 0.1958\n","Epoch 4/5\n","3/3 [==============================] - 4s 1s/step - loss: 0.8065 - custom_acc_orig_tokens: 0.7757 - custom_acc_orig_non_other_tokens: 0.2487 - val_loss: 0.5659 - val_custom_acc_orig_tokens: 0.8393 - val_custom_acc_orig_non_other_tokens: 0.4670\n","Epoch 5/5\n","3/3 [==============================] - 4s 1s/step - loss: 0.5764 - custom_acc_orig_tokens: 0.8402 - custom_acc_orig_non_other_tokens: 0.5047 - val_loss: 0.4178 - val_custom_acc_orig_tokens: 0.8790 - val_custom_acc_orig_non_other_tokens: 0.6415\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f104eff1890>"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"c2KyTCL7iIlT"},"source":[""],"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import sentencepiece\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForPreTraining, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel(\"ERROR\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/sample'\n",
    "filename = 'sample_ner.csv'\n",
    "full_path = f'{path}/{filename}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/sample/sample_ner.csv'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploring the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"giacomomiolo/scibert_reupload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [102, 1143, 11209, 239, 579, 5682, 20583, 579, 305, 579, 6090, 579, 158, 579, 145, 1502, 7972, 30111, 579, 170, 579, 18209, 7085, 546, 579, 370, 579, 260, 145, 170, 579, 1502, 13532, 4858, 11597, 9269, 579, 158, 579, 18209, 546, 6090, 1901, 8654, 13205, 260, 170, 422, 239, 579, 128, 1901, 6204, 26996, 579, 170, 422, 286, 145, 158, 30117, 422, 239, 30117, 546, 579, 346, 574, 145, 8514, 4788, 30107, 546, 103], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"Example 194 3-Isobutyl-5-methyl-1-(oxetan-2-ylmethyl)-6-[(2-oxoimidazolidin-1-yl)methyl]thieno[2,3-d]pyrimidine-2,4(1H,3H)-dione (racemate)\") #, max_length=None, padding='max_length', truncation=True)\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_input['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] example 194 3 - isobutyl - 5 - methyl - 1 - ( oxetan - [SEP]'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['evapor', '##ator']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('evaporator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate NER label list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER labels. \n",
    "    Note that the word can be tokenized to two or more tokens. \n",
    "    Correspondingly, we add - for now - custom 'X' tokens to the labels \n",
    "    in order to maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \n",
    "    *Function modified from BERT_T5_NER_2_3_030521\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponding to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    return addDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bert_ner_inputs(full_path, max_length=400):\n",
    "    \"\"\"\n",
    "    Read the file line by line and construct snippets (\"sentences\"). \n",
    "    A snippet end is marked by 'SNIPPET: [snippet id]' in the next row.\n",
    "    \n",
    "    Also, cap snippet length using max_length. \n",
    "    Snippets which are shorter than max_length are padded. \n",
    "    All snippets end with a [SEP] token, padded or not.\n",
    "    \n",
    "    arguments: full path of input file, max length of snippet\n",
    "    returns: lists for BERT inputs (bertSentenceIDs, bertMasks, bertSequenceIDs)\n",
    "             and the inputs before BERT tokenization (sentenceList, nerTokenList, sentLengthList)\n",
    "    \n",
    "    *Function modified from BERT_T5_NER_2_3_030521\n",
    "    \"\"\"\n",
    "\n",
    "    with io.open(full_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        text = f.readlines()\n",
    "\n",
    "\n",
    "    # lists for sentences, tokens, labels, etc. \n",
    "    sentenceTokenList = []\n",
    "    nerTokenList = []\n",
    "    sentLengthList = []\n",
    "\n",
    "    # lists for BERT input\n",
    "    bertSentenceIDs = []\n",
    "    bertMasks = []\n",
    "    bertSequenceIDs = []\n",
    "\n",
    "    # always start with [CLS] tokens\n",
    "    sentenceTokens = ['[CLS]']\n",
    "    nerTokens = ['[nerCLS]']\n",
    "\n",
    "    for line in text:\n",
    "        \n",
    "        parsed_line = line.strip().split('\\t')\n",
    "        \n",
    "        # if new sentence starts\n",
    "        if parsed_line[0][:8] == 'SNIPPET:':\n",
    "            \n",
    "            if len(sentenceTokens) > 1:\n",
    "            \n",
    "                # figure out sentence length for padding or truncating\n",
    "                sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "                sentLengthList.append(sentenceLength)\n",
    "\n",
    "                # Create space for at least a final '[SEP]' token\n",
    "                if sentenceLength >= max_length - 1: \n",
    "                    sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "                    nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "                # add a ['SEP'] token and padding \n",
    "                sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "                nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "\n",
    "                # append current data to lists\n",
    "                sentenceTokenList.append(sentenceTokens)\n",
    "                nerTokenList.append(nerTokens)\n",
    "\n",
    "                # generate BERT tokens\n",
    "                bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "                #bertSentenceIDs.append(tokenizer.prepare_seq2seq_batch(sentenceTokens, return_tensors='tf'))\n",
    "                bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "                bertSequenceIDs.append([0] * (max_length))\n",
    "\n",
    "                # initialize new sentence\n",
    "                sentenceTokens = ['[CLS]']\n",
    "                nerTokens = ['[nerCLS]']\n",
    "                \n",
    "        elif parsed_line[0]:            \n",
    "            word = parsed_line[0]\n",
    "            ner = parsed_line[1]\n",
    "            \n",
    "            addDict = addWord(word, ner)\n",
    "            sentenceTokens += addDict['wordToken']\n",
    "            nerTokens += addDict['nerToken']\n",
    "    \n",
    "    # take care of last sentence\n",
    "    # figure out sentence length for padding or truncating\n",
    "    sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "    sentLengthList.append(sentenceLength)\n",
    "\n",
    "    # Create space for at least a final '[SEP]' token\n",
    "    if sentenceLength >= max_length - 1: \n",
    "        sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "        nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "    # add a ['SEP'] token and padding \n",
    "    sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "    nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "\n",
    "    # append current data to lists\n",
    "    sentenceTokenList.append(sentenceTokens)\n",
    "    nerTokenList.append(nerTokens)\n",
    "\n",
    "    # generate BERT tokens\n",
    "    bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "    bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "    bertSequenceIDs.append([0] * (max_length))\n",
    "\n",
    "    return sentenceTokenList, nerTokenList, sentLengthList, bertSentenceIDs, bertMasks, bertSequenceIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceTokenList, nerTokenList, sentLengthList, bertSentenceIDs, bertMasks, bertSequenceIDs = generate_bert_ner_inputs(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nerTokenList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 400\n",
    "sentenceLengths= [l for l in sentLengthList]\n",
    "plt.hist(np.array(sentenceLengths), bins=(50))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentLengthList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAX9UlEQVR4nO3df5DV913v8edL0qYUSgKm2UGWCtWdagI2lh3Em1vnRKJZba/gjOh2UrM4cdbJUG3v5GrBcSb6x46Mox3L1DCuprLYWmZv21y4ZtAi9Ux1hpRCjBKgyFoo3bBCmzYpWx0M+L5/nE+u3yxndw/f3f0uu5/XY2bnfM/7+/2c833zHV7nnM/58VVEYGZmefiu2d4BMzOrjkPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M2mkaTzkh6c7f0wG49D38wsIw59s3FIWinps5K+LuklSR+T9H2SPp+uf0PSJyXdmbb/c+BtwP+VNCrpN2a1AbMm5J9hMLuRpAXAc8Dngd8CrgOdwL8Cq4EvAEuAzwDPRcSH0rjzwC9HxN9Uv9dmk7tttnfA7Ba1Hvge4Ncj4lqq/X26HEqXX5f0EeCJqnfOrCyHvllzK4GvFgIfAEl3A7uAdwNvoTFF+q3qd8+sHM/pmzX3NeBtksY+MfpdIIAfioglwPsBFdZ7vtRuaQ59s+aOAiPATkmLJL1J0v00nt2PAi9LWgH8+phxl4C3V7urZq1z6Js1ERHXgf8BfD9wARgGfgH4HeBdwCvAM8Bnxwz9XeC3JL0s6X9Vt8dmrfGnd8zMMuJn+mZmGXHom5llxKFvZpYRh76ZWUZu+S9n3XXXXbFq1apSY7/zne+waNGi6d2hW5x7zkNuPefWL0y95+PHj38jIt46tn7Lh/6qVas4duxYqbH1ep1arTa9O3SLc895yK3n3PqFqfcs6avN6p7eMTPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjLYW+pP8p6aSkFyR9Kv3M7DJJhySdTZdLC9vvkDQk6Yykhwr1dZJOpHW7JKn5PZqZ2UyYNPTTb4b/GtAZEWuABUA3sB04HBEdwOF0HUn3pPX3Al3Ak+l8owC7gV6gI/11TWs3ZmY2oVand24DFqazCL0ZuAhsAgbS+gFgc1reBOyLiKsRcY7G+UTXS1oOLImII9H4Pee9hTFmZlaBSb+RGxEvSvp9GieS+HfgcxHxOUltETGSthlJ5w4FWAE8W7iJ4VR7NS2Prd9AUi+NVwS0tbVRr9dvqqnXjI6Olh47V7nnPOTW82z3e+LFV0qPXbvijlLjZqrnSUM/zdVvAlYDLwP/W9L7JxrSpBYT1G8sRvQD/QCdnZ1R9qvI/up2Htzz/Dfb/W7d/kzpsecfrpUaN1M9tzK98yBwLiK+HhGv0jg93H8DLqUpG9Ll5bT9MLCyML6dxnTQcFoeWzczs4q0EvoXgA2S3pw+bbMROA0cAHrSNj3A/rR8AOiWdLuk1TTesD2apoKuSNqQbueRwhgzM6tAK3P6X5T0aeA54BrwDzSmXhYDg5IepfHAsCVtf1LSIHAqbb8tnWQa4DFgD7AQOJj+zMysIi39tHJEPAE8MaZ8lcaz/mbb9wF9TerHgDU3uY9mZjZN/I1cM7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMTBr6kt4h6fnC37clfUjSMkmHJJ1Nl0sLY3ZIGpJ0RtJDhfo6SSfSul3pXLlmZlaRSUM/Is5ExH0RcR+wDvg34GlgO3A4IjqAw+k6ku4BuoF7gS7gSUkL0s3tBnppnCy9I603M7OK3Oz0zkbgXyLiq8AmYCDVB4DNaXkTsC8irkbEOWAIWC9pObAkIo5ERAB7C2PMzKwCLZ0YvaAb+FRabouIEYCIGJF0d6qvAJ4tjBlOtVfT8tj6DST10nhFQFtbG/V6/SZ3s2F0dLT02LnKPecht55nu9/H114rPfZWy6+WQ1/SG4GfAXZMtmmTWkxQv7EY0Q/0A3R2dkatVmt1N1+nXq9Tduxc5Z7zkFvPs93v1u3PlB57/uFaqXEz1fPNTO/8FPBcRFxK1y+lKRvS5eVUHwZWFsa1AxdTvb1J3czMKnIzof8+/mtqB+AA0JOWe4D9hXq3pNslrabxhu3RNBV0RdKG9KmdRwpjzMysAi1N70h6M/ATwK8UyjuBQUmPAheALQARcVLSIHAKuAZsi4jracxjwB5gIXAw/ZmZWUVaCv2I+Dfgu8fUXqLxaZ5m2/cBfU3qx4A1N7+bZmY2HfyNXDOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMtnxjdzMxu3qqSJ1Xf07VomvekoaVn+pLulPRpSV+WdFrSj0paJumQpLPpcmlh+x2ShiSdkfRQob5O0om0blc6V66ZmVWk1emdjwJ/FRE/ALwTOA1sBw5HRAdwOF1H0j1AN3Av0AU8KWlBup3dQC+Nk6V3pPVmZlaRSUNf0hLgx4CnACLiPyLiZWATMJA2GwA2p+VNwL6IuBoR54AhYL2k5cCSiDgSEQHsLYwxM7MKtDKn/3bg68CfSXoncBz4INAWESMAETEi6e60/Qrg2cL44VR7NS2Prd9AUi+NVwS0tbVRr9db7ed1RkdHS4+dq9xzHnLrebb7fXzttcrvc6Z6biX0bwPeBfxqRHxR0kdJUznjaDZPHxPUbyxG9AP9AJ2dnVGr1VrYzRvV63XKjp2r3HMecut5tvvdWvLN2KnY07VoRnpuZU5/GBiOiC+m65+m8SBwKU3ZkC4vF7ZfWRjfDlxM9fYmdTMzq8ikoR8R/wp8TdI7UmkjcAo4APSkWg+wPy0fALol3S5pNY03bI+mqaArkjakT+08UhhjZmYVaPVz+r8KfFLSG4GvAL9E4wFjUNKjwAVgC0BEnJQ0SOOB4RqwLSKup9t5DNgDLAQOpj8zM6tIS6EfEc8DnU1WbRxn+z6gr0n9GLDmJvbPzMymkX+GwcwsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIy2FvqTzkk5Iel7SsVRbJumQpLPpcmlh+x2ShiSdkfRQob4u3c6QpF3pXLlmZlaRm3mm/0BE3BcRr502cTtwOCI6gMPpOpLuAbqBe4Eu4ElJC9KY3UAvjZOld6T1ZmZWkalM72wCBtLyALC5UN8XEVcj4hwwBKyXtBxYEhFHIiKAvYUxZmZWgZZOjA4E8DlJAfxxRPQDbRExAhARI5LuTtuuAJ4tjB1OtVfT8tj6DST10nhFQFtbG/V6vcXdfL3R0dHSY+cq95yH3Hqe7X4fX3ut8vucqZ5bDf37I+JiCvZDkr48wbbN5uljgvqNxcaDSj9AZ2dn1Gq1Fnfz9er1OmXHzlXuOQ+59Tzb/W7d/kzl97mna9GM9NzS9E5EXEyXl4GngfXApTRlQ7q8nDYfBlYWhrcDF1O9vUndzMwqMmnoS1ok6S2vLQM/CbwAHAB60mY9wP60fADolnS7pNU03rA9mqaCrkjakD6180hhjJmZVaCV6Z024On06crbgL+IiL+S9CVgUNKjwAVgC0BEnJQ0CJwCrgHbIuJ6uq3HgD3AQuBg+jMzs4pMGvoR8RXgnU3qLwEbxxnTB/Q1qR8D1tz8bpqZ2XTwN3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy0irP61sZnZLWDWFnzk+v/M907gnc5Of6ZuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZaTl0Je0QNI/SPrLdH2ZpEOSzqbLpYVtd0gaknRG0kOF+jpJJ9K6Xem0iWZmVpGbeab/QeB04fp24HBEdACH03Uk3QN0A/cCXcCTkhakMbuBXhrnze1I683MrCIthb6kduA9wJ8WypuAgbQ8AGwu1PdFxNWIOAcMAeslLQeWRMSRiAhgb2GMmZlVoNUvZ/0h8BvAWwq1togYAYiIEUl3p/oK4NnCdsOp9mpaHlu/gaReGq8IaGtro16vt7ibrzc6Olp67FzlnvOQW8/Ffh9fe6307ZT9N5vKfZY1U8d40tCX9F7gckQcl1Rr4TabzdPHBPUbixH9QD9AZ2dn1Gqt3O2N6vU6ZcfOVe45D7n1XOx361S+kftwrdS4qdxnWXu6Fs3IMW7lmf79wM9I+mngTcASSZ8ALklanp7lLwcup+2HgZWF8e3AxVRvb1I3M7OKTDqnHxE7IqI9IlbReIP28xHxfuAA0JM26wH2p+UDQLek2yWtpvGG7dE0FXRF0ob0qZ1HCmPMzKwCU/nBtZ3AoKRHgQvAFoCIOClpEDgFXAO2RcT1NOYxYA+wEDiY/szMrCI3FfoRUQfqafklYOM42/UBfU3qx4A1N7uTZmY2PfyNXDOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjEwa+pLeJOmopH+UdFLS76T6MkmHJJ1Nl0sLY3ZIGpJ0RtJDhfo6SSfSul3pXLlmZlaRVp7pXwV+PCLeCdwHdEnaAGwHDkdEB3A4XUfSPTROoH4v0AU8KWlBuq3dQC+Nk6V3pPVmZlaRSUM/GkbT1TekvwA2AQOpPgBsTsubgH0RcTUizgFDwHpJy4ElEXEkIgLYWxhjZmYVUCN/J9mo8Uz9OPD9wB9FxIclvRwRdxa2+VZELJX0MeDZiPhEqj8FHATOAzsj4sFUfzfw4Yh4b5P766XxioC2trZ1+/btK9Xc6OgoixcvLjV2rnLPecit52K/J158pfTtrF1xR6lxU7nPslbfsWBKx/iBBx44HhGdY+u3tTI4Iq4D90m6E3ha0poJNm82Tx8T1JvdXz/QD9DZ2Rm1Wq2V3bxBvV6n7Ni5yj3nIbeei/1u3f5M6ds5/3Ct1Lip3GdZe7oWzcgxvqlP70TEy0Cdxlz8pTRlQ7q8nDYbBlYWhrUDF1O9vUndzMwq0sqnd96anuEjaSHwIPBl4ADQkzbrAfan5QNAt6TbJa2m8Ybt0YgYAa5I2pA+tfNIYYyZmVWglemd5cBAmtf/LmAwIv5S0hFgUNKjwAVgC0BEnJQ0CJwCrgHb0vQQwGPAHmAhjXn+g9PZjJmZTWzS0I+IfwJ+uEn9JWDjOGP6gL4m9WPARO8HmJnZDPI3cs3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMtLKOXJXSvpbSaclnZT0wVRfJumQpLPpcmlhzA5JQ5LOSHqoUF8n6URatyudK9fMzCrSyjP9a8DjEfGDwAZgm6R7gO3A4YjoAA6n66R13cC9QBfwZDq/LsBuoJfGydI70nozM6vIpKEfESMR8VxavgKcBlYAm4CBtNkAsDktbwL2RcTViDgHDAHrJS0HlkTEkYgIYG9hjJmZVUCN/G1xY2kV8AUaJze/EBF3FtZ9KyKWSvoY8GxEfCLVnwIOAueBnRHxYKq/G/hwRLy3yf300nhFQFtb27p9+/aVam50dJTFixeXGjtXuec85NZzsd8TL75S+nbWrrij1Lip3GdZq+9YMKVj/MADDxyPiM6x9dtavQFJi4HPAB+KiG9PMB3fbEVMUL+xGNEP9AN0dnZGrVZrdTdfp16vU3bsXOWe85Bbz8V+t25/pvTtnH+4VmrcVO6zrD1di2bkGLf06R1Jb6AR+J+MiM+m8qU0ZUO6vJzqw8DKwvB24GKqtzepm5lZRVr59I6Ap4DTEfGRwqoDQE9a7gH2F+rdkm6XtJrGG7ZHI2IEuCJpQ7rNRwpjzMysAq1M79wP/CJwQtLzqfabwE5gUNKjwAVgC0BEnJQ0CJyi8cmfbRFxPY17DNgDLKQxz39wetowM7NWTBr6EfH3NJ+PB9g4zpg+oK9J/RiNN4HNzGwW+Bu5ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZaeUcuR+XdFnSC4XaMkmHJJ1Nl0sL63ZIGpJ0RtJDhfo6SSfSul3pPLlmZlahVp7p7wG6xtS2A4cjogM4nK4j6R6gG7g3jXlS0oI0ZjfQS+NE6R1NbtPMzGbYpKEfEV8AvjmmvAkYSMsDwOZCfV9EXI2Ic8AQsF7ScmBJRByJiAD2FsaYmVlFJj0x+jjaImIEICJGJN2d6iuAZwvbDafaq2l5bL0pSb00XhXQ1tZGvV4vtZOjo6Olx85V7jkPufVc7PfxtddK307Zf7Op3GdZM3WMy4b+eJrN08cE9aYioh/oB+js7IxarVZqZ+r1OmXHzlXuOQ+59Vzsd+v2Z0rfzvmHa6XGTeU+y9rTtWhGjnHZT+9cSlM2pMvLqT4MrCxs1w5cTPX2JnUzM6tQ2dA/APSk5R5gf6HeLel2SatpvGF7NE0FXZG0IX1q55HCGDMzq8ik0zuSPgXUgLskDQNPADuBQUmPAheALQARcVLSIHAKuAZsi4jr6aYeo/FJoIXAwfRnZmYVmjT0I+J946zaOM72fUBfk/oxYM1N7Z2ZmU0rfyPXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4xM9+kSbyknXnyl1GnOzu98zwzsjZnZ7JvXoT8bVpU8l6YfaMysCg79jJV9gAI/SJnNVZWHvqQu4KPAAuBPI2Jn1fswmamEoU1srj3Q+JXbxOba8bSKQ1/SAuCPgJ8AhoEvSToQEaeq3I9b0XQ90Dy+9lqp9zHmgvH+jSbr2eEyOT/RyUfVz/TXA0MR8RUASfuATTROpG5zyFwKidnY19l4BjyXjsls8b8RKCKquzPp54CuiPjldP0XgR+JiA+M2a4X6E1X3wGcKXmXdwHfKDl2rnLPecit59z6han3/L0R8daxxaqf6atJ7YZHnYjoB/qnfGfSsYjonOrtzCXuOQ+59ZxbvzBzPVf95axhYGXhejtwseJ9MDPLVtWh/yWgQ9JqSW8EuoEDFe+DmVm2Kp3eiYhrkj4A/DWNj2x+PCJOzuBdTnmKaA5yz3nIrefc+oUZ6rnSN3LNzGx2+QfXzMwy4tA3M8vIvAx9SV2SzkgakrR9tvenCpLOSzoh6XlJx2Z7f2aCpI9LuizphUJtmaRDks6my6WzuY/TbZyef1vSi+lYPy/pp2dzH6ebpJWS/lbSaUknJX0w1eftsZ6g52k/1vNuTj/91MM/U/ipB+B98/2nHiSdBzojYt5+gUXSjwGjwN6IWJNqvwd8MyJ2pgf4pRHx4dncz+k0Ts+/DYxGxO/P5r7NFEnLgeUR8ZyktwDHgc3AVubpsZ6g559nmo/1fHym//9/6iEi/gN47acebI6LiC8A3xxT3gQMpOUBGv9R5o1xep7XImIkIp5Ly1eA08AK5vGxnqDnaTcfQ38F8LXC9WFm6B/vFhPA5yQdTz9jkYu2iBiBxn8c4O5Z3p+qfEDSP6Xpn3kzzTGWpFXADwNfJJNjPaZnmOZjPR9Dv6WfepiH7o+IdwE/BWxL0wI2P+0Gvg+4DxgB/mBW92aGSFoMfAb4UER8e7b3pwpNep72Yz0fQz/Ln3qIiIvp8jLwNI1prhxcSvOhr82LXp7l/ZlxEXEpIq5HxH8Cf8I8PNaS3kAj/D4ZEZ9N5Xl9rJv1PBPHej6GfnY/9SBpUXrzB0mLgJ8EXph41LxxAOhJyz3A/lncl0q8FnzJzzLPjrUkAU8BpyPiI4VV8/ZYj9fzTBzreffpHYD0saY/5L9+6qFvdvdoZkl6O41n99D4aY2/mI89S/oUUKPxk7OXgCeA/wMMAm8DLgBbImLevPE5Ts81Gi/3AzgP/Mprc93zgaT/DvwdcAL4z1T+TRpz3PPyWE/Q8/uY5mM9L0PfzMyam4/TO2ZmNg6HvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZ+X+i6Wn8HB5H7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-EXAMPLE_LABEL</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-EXAMPLE_LABEL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-EXAMPLE_LABEL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-EXAMPLE_LABEL</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-EXAMPLE_LABEL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>nerX</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>nerX</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>nerX</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>nerX</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>nerX</td>\n",
       "      <td>25</td>\n",
       "      <td>6114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>676 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tag  cat  occurences\n",
       "0    B-EXAMPLE_LABEL    0          49\n",
       "1    B-EXAMPLE_LABEL    1           0\n",
       "2    B-EXAMPLE_LABEL    2           0\n",
       "3    B-EXAMPLE_LABEL    3           0\n",
       "4    B-EXAMPLE_LABEL    4           0\n",
       "..               ...  ...         ...\n",
       "671             nerX   21           0\n",
       "672             nerX   22           0\n",
       "673             nerX   23           0\n",
       "674             nerX   24           0\n",
       "675             nerX   25        6114\n",
       "\n",
       "[676 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>B-OTHER_COMPOUND</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>B-REACTION_PRODUCT</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>B-REACTION_STEP</td>\n",
       "      <td>3</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>108</td>\n",
       "      <td>B-REAGENT_CATALYST</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>B-SOLVENT</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162</td>\n",
       "      <td>B-STARTING_MATERIAL</td>\n",
       "      <td>6</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>189</td>\n",
       "      <td>B-TEMPERATURE</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>216</td>\n",
       "      <td>B-TIME</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>243</td>\n",
       "      <td>B-WORKUP</td>\n",
       "      <td>9</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>270</td>\n",
       "      <td>B-YIELD_OTHER</td>\n",
       "      <td>10</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>297</td>\n",
       "      <td>B-YIELD_PERCENT</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>324</td>\n",
       "      <td>I-OTHER_COMPOUND</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>351</td>\n",
       "      <td>I-REACTION_PRODUCT</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>378</td>\n",
       "      <td>I-REAGENT_CATALYST</td>\n",
       "      <td>14</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>405</td>\n",
       "      <td>I-SOLVENT</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>432</td>\n",
       "      <td>I-STARTING_MATERIAL</td>\n",
       "      <td>16</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>459</td>\n",
       "      <td>I-TEMPERATURE</td>\n",
       "      <td>17</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>486</td>\n",
       "      <td>I-TIME</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>513</td>\n",
       "      <td>I-YIELD_OTHER</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>540</td>\n",
       "      <td>I-YIELD_PERCENT</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>567</td>\n",
       "      <td>O</td>\n",
       "      <td>21</td>\n",
       "      <td>4366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>594</td>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>621</td>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>23</td>\n",
       "      <td>8018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>648</td>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>24</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>675</td>\n",
       "      <td>nerX</td>\n",
       "      <td>25</td>\n",
       "      <td>6114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                  tag  cat  occurences\n",
       "0      27     B-OTHER_COMPOUND    1         171\n",
       "1      54   B-REACTION_PRODUCT    2         109\n",
       "2      81      B-REACTION_STEP    3         172\n",
       "3     108   B-REAGENT_CATALYST    4          58\n",
       "4     135            B-SOLVENT    5          61\n",
       "5     162  B-STARTING_MATERIAL    6          88\n",
       "6     189        B-TEMPERATURE    7          74\n",
       "7     216               B-TIME    8          47\n",
       "8     243             B-WORKUP    9         120\n",
       "9     270        B-YIELD_OTHER   10          55\n",
       "10    297      B-YIELD_PERCENT   11          48\n",
       "11    324     I-OTHER_COMPOUND   12          56\n",
       "12    351   I-REACTION_PRODUCT   13          56\n",
       "13    378   I-REAGENT_CATALYST   14          39\n",
       "14    405            I-SOLVENT   15           3\n",
       "15    432  I-STARTING_MATERIAL   16          40\n",
       "16    459        I-TEMPERATURE   17          55\n",
       "17    486               I-TIME   18          46\n",
       "18    513        I-YIELD_OTHER   19          54\n",
       "19    540      I-YIELD_PERCENT   20           1\n",
       "20    567                    O   21        4366\n",
       "21    594             [nerCLS]   22          50\n",
       "22    621             [nerPAD]   23        8018\n",
       "23    648             [nerSEP]   24          50\n",
       "24    675                 nerX   25        6114"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_categories = nerDistribution.loc[(nerDistribution.iloc[:,1:]!=0).all(1)].reset_index()\n",
    "ner_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Always picking 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7569348127600555"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = int(nerDistribution.loc[nerDistribution.tag == 'O','occurences']\\\n",
    "                                .reset_index().drop(['index'], axis=1).loc[21])   # Some gymnasics to get the count..\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 22]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bert_inputs[0])\n",
    "np.random.seed(0)\n",
    "training_examples = np.random.binomial(1, 0.7, numSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSentence_ids = []\n",
    "trainMasks = []\n",
    "trainSequence_ids = []\n",
    "\n",
    "testSentence_ids = []\n",
    "testMasks = []\n",
    "testSequence_ids = []\n",
    "\n",
    "nerLabels_train =[]\n",
    "nerLabels_test = []\n",
    "\n",
    "\n",
    "for example in range(numSentences):\n",
    "    if training_examples[example] == 1:\n",
    "        trainSentence_ids.append(bert_inputs[0][example])\n",
    "        trainMasks.append(bert_inputs[1][example])\n",
    "        trainSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_train.append(nerLabels[example])\n",
    "    else:\n",
    "        testSentence_ids.append(bert_inputs[0][example])\n",
    "        testMasks.append(bert_inputs[1][example])\n",
    "        testSequence_ids.append(bert_inputs[2][example])\n",
    "        nerLabels_test.append(nerLabels[example])\n",
    "        \n",
    "X_train = np.array([trainSentence_ids,trainMasks,trainSequence_ids])\n",
    "X_test = np.array([testSentence_ids,testMasks,testSequence_ids])\n",
    "\n",
    "nerLabels_train = np.array(nerLabels_train)\n",
    "nerLabels_test = np.array(nerLabels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a parameter pair k_start, k_end to look at slices. This helps with quick tests.\n",
    "\n",
    "k_start = 0\n",
    "k_end = -1\n",
    "\n",
    "if k_end == -1:\n",
    "    k_end_train = X_train[0].shape[0]\n",
    "    k_end_test = X_test[0].shape[0]\n",
    "else:\n",
    "    k_end_train = k_end_test = k_end\n",
    "    \n",
    "\n",
    "\n",
    "bert_inputs_train_k = [X_train[0][k_start:k_end_train], X_train[1][k_start:k_end_train], \n",
    "                       X_train[2][k_start:k_end_train]]\n",
    "bert_inputs_test_k = [X_test[0][k_start:k_end_test], X_test[1][k_start:k_end_test], \n",
    "                      X_test[2][k_start:k_end_test]]\n",
    "\n",
    "\n",
    "labels_train_k = nerLabels_train[k_start:k_end_train]\n",
    "labels_test_k = nerLabels_test[k_start:k_end_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Loss & Accuracy\n",
    "(from BERT_T5_NER_2_3_030521)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a custom loss function because we only want to optimize for the labels that we actually had in the text, not the extra ones like '[nerPAD]', etc. Our cost function is therefore derived from sparse_categorical_crossentropy, but we choose to modify the function a bit: we want to mask out all tokens that have a token id larger or equal to 22, corresponding to the extra tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss function explicitly, filtering out 'extra inserted labels'\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length + 1) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns:  cost\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(Flatten()(tf.cast(y_true, tf.int32)),[-1])\n",
    "    \n",
    "    mask = (y_label < 22)   # This mask is used to remove all tokens that do not correspond to the original base text.\n",
    "\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)  # mask the labels\n",
    "    \n",
    "    y_flat_pred = tf.reshape(Flatten()(tf.cast(y_pred, tf.float32)),[-1, numNerClasses])\n",
    "    \n",
    "    y_flat_pred_masked = tf.boolean_mask(y_flat_pred, mask) # mask the predictions\n",
    "    \n",
    "    return tf.reduce_mean(sparse_categorical_crossentropy(y_label_masked, y_flat_pred_masked,from_logits=False ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction filtering out also the newly inserted labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 22)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_acc_orig_non_other_tokens(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    calculate loss dfunction explicitly filtering out also the 'Other'- labels\n",
    "    \n",
    "    y_true: Shape: (batch x (max_length) )\n",
    "    y_pred: predictions. Shape: (batch x x (max_length + 1) x num_distinct_ner_tokens ) \n",
    "    \n",
    "    returns: accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    #get labels and predictions\n",
    "    \n",
    "    y_label = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_true, tf.int64)),[-1])\n",
    "    \n",
    "    mask = (y_label < 21)\n",
    "    y_label_masked = tf.boolean_mask(y_label, mask)\n",
    "    \n",
    "    y_predicted = tf.math.argmax(input = tf.reshape(tf.keras.layers.Flatten()(tf.cast(y_pred, tf.float64)),\\\n",
    "                                                    [-1, numNerClasses]), axis=1)\n",
    "    \n",
    "    y_predicted_masked = tf.boolean_mask(y_predicted, mask)\n",
    "\n",
    "    return tf.reduce_mean(tf.cast(tf.equal(y_predicted_masked,y_label_masked) , dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_customized = tf.keras.optimizers.Adam(learning_rate=0.0005, beta_1=0.91, beta_2=0.999, epsilon=None, decay=0.1, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_model(max_input_length, train_layers, optimizer):\n",
    "    \"\"\"\n",
    "    Implementation of NER model\n",
    "    \n",
    "    variables:\n",
    "        max_input_length: number of tokens (max_length + 1)\n",
    "        train_layers: number of layers to be retrained\n",
    "        optimizer: optimizer to be used\n",
    "    \n",
    "    returns: model\n",
    "    \"\"\"\n",
    "    \n",
    "    in_id = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_length,), dtype='int32', name=\"segment_ids\")\n",
    "    \n",
    "    \n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Note: Bert layer from Hugging Face returns two values: sequence ouput, and pooled output. Here, we only want\n",
    "    # the former. (See https://huggingface.co/transformers/model_doc/bert.html#tfbertmodel) \n",
    "    \n",
    "    bert_layer = TFAutoModel.from_pretrained(\"giacomomiolo/scibert_reupload\")\n",
    "    \n",
    "    # Freeze layers, i.e. only train number of layers specified, starting from the top\n",
    "    \n",
    "#     if not train_layers == -1:\n",
    "        \n",
    "#         retrain_layers = []\n",
    "    \n",
    "#         for retrain_layer_number in range(train_layers):\n",
    "\n",
    "#             layer_code = '_' + str(11 - retrain_layer_number)\n",
    "#             retrain_layers.append(layer_code)\n",
    "\n",
    "#         for w in bert_layer.weights:\n",
    "#             if not any([x in w.name for x in retrain_layers]):\n",
    "#                 w._trainable = False\n",
    "\n",
    "        # End of freezing section\n",
    "    \n",
    "    bert_sequence = bert_layer(bert_inputs)[0]\n",
    "    \n",
    "    print('Let us check the shape of the BERT layer output:', bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dense(256, activation='relu', name='dense')(bert_sequence)\n",
    "    \n",
    "    dense = tf.keras.layers.Dropout(rate=0.1)(dense)\n",
    "    \n",
    "    pred = tf.keras.layers.Dense(26, activation='softmax', name='ner')(dense)\n",
    "     \n",
    "    print('pred: ', pred)\n",
    "    \n",
    "    ## Prepare for multipe loss functions, although not used here\n",
    "    \n",
    "    losses = {\n",
    "        \"ner\": custom_loss,\n",
    "        }\n",
    "    lossWeights = {\"ner\": 1.0\n",
    "                  }\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "\n",
    "    model.compile(loss=losses, optimizer=optimizer, metrics=[custom_acc_orig_tokens, \n",
    "                                                          custom_acc_orig_non_other_tokens])\n",
    "    \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d40c4d8f54e45798b565b85f9ed85a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=439936168.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at giacomomiolo/scibert_reupload.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let us check the shape of the BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 400, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "pred:  KerasTensor(type_spec=TensorSpec(shape=(None, 400, 26), dtype=tf.float32, name=None), name='ner/Softmax:0', description=\"created by layer 'ner'\")\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 400)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109918464   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 400, 256)     196864      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 400, 256)     0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "ner (Dense)                     (None, 400, 26)      6682        dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 110,122,010\n",
      "Trainable params: 110,122,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/8\n",
      "2/2 [==============================] - 125s 15s/step - loss: 3.5968 - custom_acc_orig_tokens: 0.3895 - custom_acc_orig_non_other_tokens: 0.0197 - val_loss: 4.4801 - val_custom_acc_orig_tokens: 0.0111 - val_custom_acc_orig_non_other_tokens: 0.0434\n",
      "Epoch 2/8\n",
      "2/2 [==============================] - 83s 11s/step - loss: 4.3790 - custom_acc_orig_tokens: 0.3768 - custom_acc_orig_non_other_tokens: 0.0306 - val_loss: 1.4712 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 3/8\n",
      "2/2 [==============================] - 81s 12s/step - loss: 6.2555 - custom_acc_orig_tokens: 0.3826 - custom_acc_orig_non_other_tokens: 0.0258 - val_loss: 1.6238 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 4/8\n",
      "2/2 [==============================] - 84s 11s/step - loss: 1.6839 - custom_acc_orig_tokens: 0.3871 - custom_acc_orig_non_other_tokens: 0.0187 - val_loss: 1.4325 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 5/8\n",
      "2/2 [==============================] - 74s 11s/step - loss: 1.3510 - custom_acc_orig_tokens: 0.7629 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.4972 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 6/8\n",
      "2/2 [==============================] - 74s 11s/step - loss: 1.4999 - custom_acc_orig_tokens: 0.7651 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.6176 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 7/8\n",
      "2/2 [==============================] - 75s 11s/step - loss: 1.4774 - custom_acc_orig_tokens: 0.7558 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.3405 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n",
      "Epoch 8/8\n",
      "2/2 [==============================] - 74s 11s/step - loss: 1.3106 - custom_acc_orig_tokens: 0.7640 - custom_acc_orig_non_other_tokens: 0.0000e+00 - val_loss: 1.3156 - val_custom_acc_orig_tokens: 0.7448 - val_custom_acc_orig_non_other_tokens: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb65aad4ac0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ner_model(max_length + 1,train_layers=0,optimizer='adam')\n",
    "\n",
    "# Instantiate variables\n",
    "\n",
    "model.fit(\n",
    "    bert_inputs_train_k, \n",
    "    {\"ner\": labels_train_k },\n",
    "    validation_data=(bert_inputs_test_k, {\"ner\": labels_test_k}),\n",
    "    epochs=8,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

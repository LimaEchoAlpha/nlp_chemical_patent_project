{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"colab_trial_run.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3QJ_ExX95C8m"},"source":["#### Set-up for Colab\n","Install dependencies, mount drive, etc."]},{"cell_type":"code","metadata":{"id":"Jo_tjwx24E-H"},"source":["pip install -q -U tensorflow-text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a01FnU6G41Jv"},"source":["pip install -q tf-models-official==2.4.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYhBoz05pFKY"},"source":["pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDnftLbNfrPS"},"source":["pip install bert-for-tf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRkiRSVko_DV","executionInfo":{"status":"ok","timestamp":1637514975487,"user_tz":300,"elapsed":17640,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}},"outputId":"6944a8b3-7754-4d66-f545-ae5fd78a2c40"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"qbwOc84554BS","executionInfo":{"status":"ok","timestamp":1637515074563,"user_tz":300,"elapsed":99,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}}},"source":["path = 'drive/MyDrive/MIDS/chemical_patent_cer_ee'"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKnEMa6zo32N"},"source":["#### Import Libraries"]},{"cell_type":"code","metadata":{"id":"CckxGheg4_bq","executionInfo":{"status":"ok","timestamp":1637515060737,"user_tz":300,"elapsed":4159,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}}},"source":["import os\n","import io\n","import re\n","import sys\n","import sys\n","sys.path.append('/content/drive/MyDrive/MIDS/chemical_patent_cer_ee/notebooks')\n","\n","import numpy as np\n","import pandas as pd\n","import argparse\n","from time import time\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","from csv import reader\n","\n","import tensorflow as tf\n","from transformers import BertTokenizer\n","import bert\n","\n","from sre_inputs import *\n","from train_test import *\n","from sre_models import *"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frzxEMlBo32P"},"source":["#### BERT Model\n","- Load BERT model and tokenizer\n","- Set max length for inputs"]},{"cell_type":"code","metadata":{"id":"7ECV6hEuo32Q","executionInfo":{"status":"ok","timestamp":1637515080098,"user_tz":300,"elapsed":854,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}}},"source":["# path for bert model\n","bert_model_dir = f'{path}/bert/scibert_scivocab_cased'\n","\n","# set tokenizer\n","vocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\n","tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False)\n","\n","# set BERT model\n","bert_params = bert.params_from_pretrained_ckpt(bert_model_dir)\n","bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n","\n","# set max length for inputs\n","max_length = 500"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bSF2-2aJ8m7k"},"source":["#### Data\n","- Upload preprocessed chemical patent file(s)\n","- Use `sre_inputs` module to generate inputs for model\n","- Sample only: split into train/test using `train_test` module\n","- Need to one hot encode labels before using in model\n","\n","*NB: Make sure that preprocessed data being uploaded and parameters chosen for generating inputs **both** match the type of model it will be used for!*"]},{"cell_type":"code","metadata":{"id":"DeO-o0ko-bjO"},"source":["#### TRAIN/DEV DATASET PROCESSING ####\n","\n","# paths for preprocessed data\n","train_path = f'{path}/data/sre_em/sre_em_train.csv'\n","dev_path = f'{path}/data/sre_em/sre_em_dev.csv'\n","\n","# indicate parameters for generating inputs\n","marker_type = 'em'\n","head_type = 'start'\n","\n","# generate inputs for model\n","train_lists = generate_entity_inputs(train_path, tokenizer, marker_type, head_type, max_length)\n","dev_lists = generate_entity_inputs(dev_path, tokenizer, marker_type, head_type, max_length)\n","\n","# generate inputs and labels\n","# one hot encode labels\n","model_inputs_train = [x for x in train_lists[0][:5]]\n","train_labels = train_lists[1]\n","model_labels_train = tf.one_hot(train_labels, depth=2)\n","\n","model_inputs_dev = [x for x in dev_lists[0][:5]]\n","dev_labels = dev_lists[1]\n","model_labels_dev = tf.one_hot(dev_labels, depth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uz_cBjKCfrPY"},"source":["#### TEST DATASET PROCESSING ####\n","\n","# path for preprocessed data\n","test_path = f'{path}/data/sre_em/sre_em_test.csv'\n","\n","# indicate parameters for generating inputs\n","marker_type = 'em'\n","head_type = 'start'\n","\n","# generate inputs for model\n","test_lists = generate_entity_inputs(test_path, tokenizer, marker_type, head_type, max_length)\n","\n","# generate inputs and labels\n","# one hot encode labels\n","model_inputs_test = [x for x in test_lists[0][:5]]\n","test_labels = test_lists[1]\n","model_labels_test = tf.one_hot(test_labels, depth=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fBiNc5Vmo32T","executionInfo":{"status":"ok","timestamp":1637515092372,"user_tz":300,"elapsed":6756,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}}},"source":["#### SAMPLE PROCESSING ####\n","\n","# path for preprocessed data\n","full_path = f'{path}/data/sre_em/sre_em_sample.csv'\n","\n","# indicate which model the data will be used for\n","marker_type = 'em'\n","head_type = 'start'\n","\n","# generate inputs for model\n","all_lists = generate_entity_inputs(full_path, tokenizer, marker_type, head_type, max_length=500)\n","\n","# SAMPLE ONLY: split into train/test\n","train_all, test_all = train_test_split(all_lists)\n","\n","# generate inputs and labels\n","# one hot encode labels\n","model_inputs_train = [x for x in train_all[0][:5]]\n","model_labels_train = train_all[1]\n","model_labels_train = tf.one_hot(model_labels_train, depth=2)\n","\n","model_inputs_test = [x for x in test_all[0][:5]]\n","model_labels_test = test_all[1]\n","model_labels_test = tf.one_hot(model_labels_test, depth=2)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TweKc5oMo32T"},"source":["#### Run Model(s)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":664},"id":"3BZ9t2fvo32U","executionInfo":{"status":"error","timestamp":1637515121738,"user_tz":300,"elapsed":972,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"}},"outputId":"c7b02b99-0f58-4394-9be4-052bd6a01ba7"},"source":["#### SAMPLE RUN ####\n","\n","tf.keras.backend.clear_session()\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","model = sre_start_model(bert, max_length)\n","\n","model.fit(\n","    model_inputs_train, \n","    {\"sre\": model_labels_train},\n","    validation_data=(model_inputs_test, {\"sre\": model_labels_test}),\n","    epochs=1,\n","    batch_size=16\n",")"],"execution_count":7,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-f3df1a01812d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_start_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m model.fit(\n","\u001b[0;32m/content/drive/MyDrive/MIDS/chemical_patent_cer_ee/notebooks/sre_models.py\u001b[0m in \u001b[0;36msre_start_model\u001b[0;34m(bert_model, max_length, train_layers)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# end of freezing section\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# apply masks to pick out start entity tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"bert\" (type BertModelLayer).\n\nin user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/bert/model.py\", line 80, in call  *\n        output           = self.encoders_layer(embedding_output, mask=mask, training=training)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.7/dist-packages/bert/transformer.py\", line 209, in build\n        self.input_spec = keras.layers.InputSpec(shape=input_shape)\n\n    TypeError: Layer input_spec must be an instance of InputSpec. Got: InputSpec(shape=(None, 500, 768), ndim=3)\n\n\nCall arguments received:\n  • inputs=['tf.Tensor(shape=(None, 500), dtype=int32)', 'tf.Tensor(shape=(None, 500), dtype=int32)']\n  • mask=None\n  • training=None"]}]},{"cell_type":"code","metadata":{"id":"1VPA3miEfrPa"},"source":["#### TRAIN/DEV RUN ####\n","\n","tf.keras.backend.clear_session()\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","model = sre_start_model(bert_model, max_length)\n","\n","model.fit(\n","    model_inputs_train, \n","    {\"sre\": model_labels_train},\n","    validation_data=(model_inputs_dev, {\"sre\": model_labels_dev}),\n","    epochs=5,\n","    batch_size=16\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rV0shhro32V"},"source":["# OPTIONAL: visualize model\n","#tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlKiGjCuo32W"},"source":["# save model\n","model_name = 'sample'\n","model.save(f'{path}/models/{model_name}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KN-Qj8bvCPgA"},"source":[""],"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"colab_mini_ner_ner_10.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3QJ_ExX95C8m"},"source":["#### Set-up for Colab\n","Install dependencies, mount drive, etc."]},{"cell_type":"code","metadata":{"id":"Jo_tjwx24E-H"},"source":["#pip install -q -U tensorflow-text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a01FnU6G41Jv"},"source":["#pip install -q tf-models-official==2.4.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3010CS9AlEG"},"source":["pip uninstall tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"25krHFUkAlEG"},"source":["pip install tensorflow==2.5.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nYhBoz05pFKY"},"source":["pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XEkMeci5rW0L"},"source":["pip install bert-for-tf2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRkiRSVko_DV","executionInfo":{"elapsed":101,"status":"ok","timestamp":1637847850668,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"},"user_tz":300},"outputId":"03b983ee-0256-4180-ed08-ab6bc1caaaca"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"qbwOc84554BS"},"source":["path = 'drive/MyDrive/MIDS/chemical_patent_cer_ee'\n","# path = '..'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pKnEMa6zo32N"},"source":["#### Import Libraries"]},{"cell_type":"code","metadata":{"id":"CckxGheg4_bq"},"source":["import os\n","import io\n","import re\n","import sys\n","import sys\n","sys.path.append('/content/drive/MyDrive/MIDS/chemical_patent_cer_ee/notebooks')\n","\n","import numpy as np\n","import pandas as pd\n","import argparse\n","from time import time\n","import matplotlib.pyplot as plt\n","\n","import pickle\n","from csv import reader\n","\n","import tensorflow as tf\n","from transformers import BertTokenizer\n","import bert\n","\n","from sre_inputs import *\n","from train_test import *\n","from sre_models import *"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"frzxEMlBo32P"},"source":["#### BERT Model\n","- Load BERT model and tokenizer\n","- Set max length for inputs"]},{"cell_type":"code","metadata":{"id":"7ECV6hEuo32Q"},"source":["# path for bert model\n","bert_model_dir = f'{path}/bert/bert_mini'\n","bert_type = bert_model_dir.split('/')[-1]\n","\n","# set tokenizer\n","vocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\n","tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False)\n","\n","# set BERT model\n","bert_params = bert.params_from_pretrained_ckpt(bert_model_dir)\n","bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n","\n","# set max length for inputs\n","max_length = 512\n","\n","# set parameters for model type\n","marker_type = 'ner' # 'em', 'ner', or 'std'\n","head_type = 'ner' # 'cls', 'start', 'pool', or 'ner'\n","subsampled = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bSF2-2aJ8m7k"},"source":["#### Data\n","- Upload preprocessed chemical patent file(s)\n","- Use `sre_inputs` module to generate inputs for model\n","- Sample only: split into train/test using `train_test` module\n","- Need to one hot encode labels before using in model\n","\n","*NB: Make sure that preprocessed data being uploaded and parameters chosen for generating inputs **both** match the type of model it will be used for!*"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeO-o0ko-bjO","executionInfo":{"elapsed":155841,"status":"ok","timestamp":1637852536609,"user":{"displayName":"Lea Cleary","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64","userId":"16569730562812745412"},"user_tz":300},"outputId":"39d04076-a875-4cd3-cffa-59ee1dec02c7"},"source":["#### TRAIN/DEV DATASET PROCESSING ####\n","\n","# paths for preprocessed data\n","if (marker_type == 'em' or marker_type == 'std') and not subsampled:\n","    train_path = f'{path}/data/sre_em/sre_em_train.csv'\n","    dev_path = f'{path}/data/sre_em/sre_em_dev.csv'\n","elif (marker_type == 'em' or marker_type == 'std') and subsampled:\n","    train_path = f'{path}/data/sre_em/sre_em_train_subsampled.csv'\n","    dev_path = f'{path}/data/sre_em/sre_em_dev_subsampled.csv'\n","elif marker_type == 'ner' and not subsampled:\n","    train_path = f'{path}/data/sre_ner/sre_ner_train.csv'\n","    dev_path = f'{path}/data/sre_ner/sre_ner_dev.csv'\n","elif marker_type == 'ner' and subsampled:\n","    train_path = f'{path}/data/sre_ner/sre_ner_train_subsampled.csv'\n","    dev_path = f'{path}/data/sre_ner/sre_ner_dev_subsampled.csv'\n","\n","print(f'Loaded {train_path}')\n","print(f'Loaded {dev_path}')\n","\n","# generate inputs for model\n","if marker_type == 'em' or marker_type == 'ner':\n","    train_lists = generate_entity_inputs(train_path, tokenizer, marker_type, head_type, max_length)\n","    dev_lists = generate_entity_inputs(dev_path, tokenizer, marker_type, head_type, max_length)\n","elif marker_type == 'std':\n","    train_lists = generate_standard_inputs(train_path, tokenizer, max_length)\n","    dev_lists = generate_standard_inputs(dev_path, tokenizer, max_length)\n","\n","# generate inputs and labels\n","# one hot encode labels\n","model_inputs_train = [x for x in train_lists[0][:5]]\n","train_labels = train_lists[1]\n","model_labels_train = tf.one_hot(train_labels, depth=3)\n","\n","model_inputs_dev = [x for x in dev_lists[0][:5]]\n","dev_labels = dev_lists[1]\n","model_labels_dev = tf.one_hot(dev_labels, depth=3)"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded drive/MyDrive/MIDS/chemical_patent_cer_ee/data/sre_ner/sre_ner_train.csv\n","Loaded drive/MyDrive/MIDS/chemical_patent_cer_ee/data/sre_ner/sre_ner_dev.csv\n"]}]},{"cell_type":"code","metadata":{"id":"by_OKfjhrW0R"},"source":["#### TEST DATASET PROCESSING ####\n","\n","# path for preprocessed data\n","if marker_type == 'em' or marker_type == 'std':\n","    test_path = f'{path}/data/sre_em/sre_em_test.csv'\n","elif marker_type == 'ner':\n","    test_path = f'{path}/data/sre_ner/sre_ner_test.csv'\n","\n","# generate inputs for model\n","if marker_type == 'em' or marker_type == 'ner':\n","    test_lists = generate_entity_inputs(test_path, tokenizer, marker_type, head_type, max_length)\n","elif marker_type == 'std':\n","    test_lists = generate_standard_inputs(test_path, tokenizer, max_length)\n","\n","# generate inputs and labels\n","# one hot encode labels\n","model_inputs_test = [x for x in test_lists[0][:5]]\n","test_labels = test_lists[1]\n","model_labels_test = tf.one_hot(test_labels, depth=3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TweKc5oMo32T"},"source":["#### Run Model(s)"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"ZEgXMIZxrW0S","outputId":"d9bd7039-c6c7-40c5-b7b2-8fd9ae18e096"},"source":["#### TRAIN/DEV RUN ####\n","\n","tf.keras.backend.clear_session()\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","epochs = 10\n","batch_size = 32\n","train_layers = 0\n","\n","if head_type == 'cls':\n","    model = sre_cls_model(bert, max_length, train_layers)\n","elif head_type == 'start':\n","    model = sre_start_model(bert, max_length, train_layers)\n","elif head_type == 'pool':\n","    model = sre_pool_model(bert, max_length, train_layers)\n","elif head_type == 'ner':\n","    model = sre_pool_model(bert, max_length, train_layers)\n","\n","if marker_type == 'std' or head_type == 'cls':\n","    model.fit(\n","        model_inputs_train[:3], \n","        {\"sre\": model_labels_train},\n","        validation_data=(model_inputs_dev[:3], {\"sre\": model_labels_dev}),\n","        epochs=epochs,\n","        batch_size=batch_size\n","    )\n","else:\n","    model.fit(\n","    model_inputs_train, \n","    {\"sre\": model_labels_train},\n","    validation_data=(model_inputs_dev, {\"sre\": model_labels_dev}),\n","    epochs=epochs,\n","    batch_size=batch_size\n",")"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["\n","=== SRE Max Pool Model ===\n","BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 512, 256), dtype=tf.float32, name=None), name='bert/encoder/layer_3/output/LayerNorm/add_1:0', description=\"created by layer 'bert'\")\n","Prediction: KerasTensor(type_spec=TensorSpec(shape=(None, 3), dtype=tf.float32, name=None), name='sre/Softmax:0', description=\"created by layer 'sre'\")\n","\n","Model: \"sre_pool\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_ids (InputLayer)          [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","segment_ids (InputLayer)        [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","e1_mask (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","e2_mask (InputLayer)            [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","bert (BertModelLayer)           (None, 512, 256)     11104768    input_ids[0][0]                  \n","                                                                 segment_ids[0][0]                \n","__________________________________________________________________________________________________\n","tf.convert_to_tensor_1 (TFOpLam (None, 512)          0           e1_mask[0][0]                    \n","__________________________________________________________________________________________________\n","tf.convert_to_tensor_3 (TFOpLam (None, 512)          0           e2_mask[0][0]                    \n","__________________________________________________________________________________________________\n","tf.convert_to_tensor (TFOpLambd (None, 512, 256)     0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","tf.math.count_nonzero (TFOpLamb (None,)              0           tf.convert_to_tensor_1[0][0]     \n","__________________________________________________________________________________________________\n","tf.convert_to_tensor_2 (TFOpLam (None, 512, 256)     0           bert[0][0]                       \n","__________________________________________________________________________________________________\n","tf.math.count_nonzero_1 (TFOpLa (None,)              0           tf.convert_to_tensor_3[0][0]     \n","__________________________________________________________________________________________________\n","tf.compat.v1.boolean_mask (Slic (None, 256)          0           tf.convert_to_tensor[0][0]       \n","                                                                 tf.convert_to_tensor_1[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape (TFOpLambda)         (None,)              0           tf.math.count_nonzero[0][0]      \n","__________________________________________________________________________________________________\n","tf.compat.v1.boolean_mask_1 (Sl (None, 256)          0           tf.convert_to_tensor_2[0][0]     \n","                                                                 tf.convert_to_tensor_3[0][0]     \n","__________________________________________________________________________________________________\n","tf.reshape_1 (TFOpLambda)       (None,)              0           tf.math.count_nonzero_1[0][0]    \n","__________________________________________________________________________________________________\n","tf.RaggedTensor.from_row_length (None, None, 256)    0           tf.compat.v1.boolean_mask[0][0]  \n","                                                                 tf.reshape[0][0]                 \n","__________________________________________________________________________________________________\n","tf.RaggedTensor.from_row_length (None, None, 256)    0           tf.compat.v1.boolean_mask_1[0][0]\n","                                                                 tf.reshape_1[0][0]               \n","__________________________________________________________________________________________________\n","input.to_tensor (InstanceMethod (None, None, 256)    0           tf.RaggedTensor.from_row_lengths[\n","__________________________________________________________________________________________________\n","input.to_tensor_1 (InstanceMeth (None, None, 256)    0           tf.RaggedTensor.from_row_lengths_\n","__________________________________________________________________________________________________\n","tf.math.reduce_max (TFOpLambda) (None, 256)          0           input.to_tensor[0][0]            \n","__________________________________________________________________________________________________\n","tf.math.reduce_max_1 (TFOpLambd (None, 256)          0           input.to_tensor_1[0][0]          \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 512)          0           tf.math.reduce_max[0][0]         \n","                                                                 tf.math.reduce_max_1[0][0]       \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 256)          131328      concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 512)]        0                                            \n","__________________________________________________________________________________________________\n","sre (Dense)                     (None, 3)            771         dropout[0][0]                    \n","==================================================================================================\n","Total params: 11,236,867\n","Trainable params: 11,236,867\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/10\n","1432/1432 [==============================] - 3336s 2s/step - loss: 0.4602 - categorical_accuracy: 0.8116 - recall: 0.7873 - precision: 0.8305 - val_loss: 0.2865 - val_categorical_accuracy: 0.8861 - val_recall: 0.8812 - val_precision: 0.8915\n","Epoch 2/10\n","1432/1432 [==============================] - 3086s 2s/step - loss: 0.2673 - categorical_accuracy: 0.8943 - recall: 0.8890 - precision: 0.8983 - val_loss: 0.2731 - val_categorical_accuracy: 0.8957 - val_recall: 0.8929 - val_precision: 0.8973\n","Epoch 3/10\n","1432/1432 [==============================] - 3088s 2s/step - loss: 0.2215 - categorical_accuracy: 0.9143 - recall: 0.9114 - precision: 0.9172 - val_loss: 0.2292 - val_categorical_accuracy: 0.9142 - val_recall: 0.9121 - val_precision: 0.9159\n","Epoch 4/10\n","1432/1432 [==============================] - 3129s 2s/step - loss: 0.1898 - categorical_accuracy: 0.9274 - recall: 0.9253 - precision: 0.9291 - val_loss: 0.2027 - val_categorical_accuracy: 0.9269 - val_recall: 0.9251 - val_precision: 0.9275\n","Epoch 5/10\n","1432/1432 [==============================] - 3137s 2s/step - loss: 0.1654 - categorical_accuracy: 0.9373 - recall: 0.9352 - precision: 0.9387 - val_loss: 0.1895 - val_categorical_accuracy: 0.9312 - val_recall: 0.9289 - val_precision: 0.9323\n","Epoch 6/10\n","1432/1432 [==============================] - 3140s 2s/step - loss: 0.1468 - categorical_accuracy: 0.9441 - recall: 0.9427 - precision: 0.9456 - val_loss: 0.1873 - val_categorical_accuracy: 0.9332 - val_recall: 0.9314 - val_precision: 0.9341\n","Epoch 7/10\n","1432/1432 [==============================] - 3111s 2s/step - loss: 0.1297 - categorical_accuracy: 0.9511 - recall: 0.9497 - precision: 0.9522 - val_loss: 0.2107 - val_categorical_accuracy: 0.9249 - val_recall: 0.9237 - val_precision: 0.9258\n","Epoch 8/10\n","1432/1432 [==============================] - 3094s 2s/step - loss: 0.1152 - categorical_accuracy: 0.9575 - recall: 0.9563 - precision: 0.9584 - val_loss: 0.1549 - val_categorical_accuracy: 0.9458 - val_recall: 0.9450 - val_precision: 0.9468\n","Epoch 9/10\n","1432/1432 [==============================] - 3093s 2s/step - loss: 0.1051 - categorical_accuracy: 0.9611 - recall: 0.9601 - precision: 0.9622 - val_loss: 0.1603 - val_categorical_accuracy: 0.9473 - val_recall: 0.9467 - val_precision: 0.9478\n","Epoch 10/10\n","1432/1432 [==============================] - 3090s 2s/step - loss: 0.0919 - categorical_accuracy: 0.9667 - recall: 0.9656 - precision: 0.9677 - val_loss: 0.1567 - val_categorical_accuracy: 0.9479 - val_recall: 0.9473 - val_precision: 0.9487\n"]}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"dmYP7G1SAlEP","outputId":"be7b33bd-0d7d-4ea4-9796-0799a78a056f"},"source":["# evaluate model on test data\n","print('Evaluate on test data')\n","\n","if marker_type == 'std' or head_type == 'cls':\n","    results = model.evaluate(model_inputs_test[:3], model_labels_test, batch_size=batch_size)\n","else:\n","    results = model.evaluate(model_inputs_test, model_labels_test, batch_size=batch_size)\n","\n","# generate predictions on new data (probabilities -- the output of the last layer)\n","print(\"Generate predictions for new samples\")\n","\n","if marker_type == 'std' or head_type == 'cls':\n","    predictions = model.predict(model_inputs_test[:3])\n","else: \n","    predictions = model.predict(model_inputs_test)\n","\n","print(\"predictions shape:\", predictions.shape)\n","\n","# save stuff\n","if subsampled:\n","    model_name = f'SRE_{bert_type}_{marker_type}_{head_type}_sub'\n","else:\n","    model_name = f'SRE_{bert_type}_{marker_type}_{head_type}'\n","\n","# save results and predictions\n","outputs = [results, predictions]\n","with open(f'{path}/results/{model_name}.pickle', \"wb\") as f:\n","    pickle.dump(outputs, f)\n","\n","# save model\n","# model.save(f'{path}/models/{model_name}')"],"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluate on test data\n","579/579 [==============================] - 372s 640ms/step - loss: 0.1609 - categorical_accuracy: 0.9457 - recall: 0.9449 - precision: 0.9466\n","Generate predictions for new samples\n","predictions shape: (18515, 3)\n"]}]},{"cell_type":"code","metadata":{"id":"Pg7AL6ZvAlEP"},"source":["# # how to open saved file\n","# with open(f'{path}/results/{model_name}.pickle', \"rb\") as f:\n","#     saved_outputs = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rV0shhro32V"},"source":["# OPTIONAL: visualize model\n","#tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KN-Qj8bvCPgA"},"source":[""],"execution_count":null,"outputs":[]}]}
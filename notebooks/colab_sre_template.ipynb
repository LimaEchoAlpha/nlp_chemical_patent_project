{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QJ_ExX95C8m"
   },
   "source": [
    "#### Set-up for Colab\n",
    "Install dependencies, mount drive, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3553,
     "status": "ok",
     "timestamp": 1637472237730,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "Jo_tjwx24E-H"
   },
   "outputs": [],
   "source": [
    "pip install -q -U tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3891,
     "status": "ok",
     "timestamp": 1637472243380,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "a01FnU6G41Jv"
   },
   "outputs": [],
   "source": [
    "pip install -q tf-models-official==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYhBoz05pFKY"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19385,
     "status": "ok",
     "timestamp": 1637467098968,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "KRkiRSVko_DV",
    "outputId": "1ccba214-96c6-4394-e584-a061830fa7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1637472718141,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "qbwOc84554BS"
   },
   "outputs": [],
   "source": [
    "path = 'drive/MyDrive/MIDS/chemical_patent_cer_ee'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKnEMa6zo32N"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3608,
     "status": "ok",
     "timestamp": 1637472723438,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "CckxGheg4_bq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/MIDS/chemical_patent_cer_ee/notebooks')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import bert\n",
    "\n",
    "from sre_inputs import *\n",
    "from train_test import *\n",
    "from sre_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frzxEMlBo32P"
   },
   "source": [
    "#### BERT Model\n",
    "- Load BERT model and tokenizer\n",
    "- Set max length for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2900,
     "status": "ok",
     "timestamp": 1637472729128,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "7ECV6hEuo32Q",
    "outputId": "26d55830-c22e-4c5f-f19a-971bcfc18da2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# path for bert model\n",
    "bert_model_dir = f'{path}/bert/scibert_scivocab_cased'\n",
    "\n",
    "# set tokenizer\n",
    "vocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\n",
    "tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False)\n",
    "\n",
    "# set BERT model\n",
    "bert_params = bert.params_from_pretrained_ckpt(bert_model_dir)\n",
    "bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "# set max length for inputs\n",
    "max_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSF2-2aJ8m7k"
   },
   "source": [
    "#### Data\n",
    "- Upload preprocessed chemical patent file(s)\n",
    "- Use `sre_inputs` module to generate inputs for model\n",
    "- Sample only: split into train/test using `train_test` module\n",
    "- Need to one hot encode labels before using in model\n",
    "\n",
    "*NB: Make sure that preprocessed data being uploaded and parameters chosen for generating inputs **both** match the type of model it will be used for!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1637472732928,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "DeO-o0ko-bjO"
   },
   "outputs": [],
   "source": [
    "#### TRAIN/DEV DATASET PROCESSING ####\n",
    "\n",
    "# paths for preprocessed data\n",
    "train_path = f'{path}/data/sre_em/sre_em_train.csv'\n",
    "dev_path = f'{path}/data/sre_em/sre_em_dev.csv'\n",
    "\n",
    "# indicate parameters for generating inputs\n",
    "marker_type = 'em'\n",
    "head_type = 'start'\n",
    "\n",
    "# generate inputs for model\n",
    "train_lists = generate_entity_inputs(train_path, tokenizer, marker_type, head_type, max_length)\n",
    "dev_lists = generate_entity_inputs(dev_path, tokenizer, marker_type, head_type, max_length)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "model_inputs_train = [x for x in train_lists[0][:5]]\n",
    "train_labels = train_lists[1]\n",
    "model_labels_train = tf.one_hot(train_labels, depth=2)\n",
    "\n",
    "model_inputs_dev = [x for x in dev_lists[0][:5]]\n",
    "dev_labels = dev_lists[1]\n",
    "model_labels_dev = tf.one_hot(dev_labels, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TEST DATASET PROCESSING ####\n",
    "\n",
    "# path for preprocessed data\n",
    "test_path = f'{path}/data/sre_em/sre_em_test.csv'\n",
    "\n",
    "# indicate parameters for generating inputs\n",
    "marker_type = 'em'\n",
    "head_type = 'start'\n",
    "\n",
    "# generate inputs for model\n",
    "test_lists = generate_entity_inputs(test_path, tokenizer, marker_type, head_type, max_length)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "model_inputs_test = [x for x in test_lists[0][:5]]\n",
    "test_labels = test_lists[1]\n",
    "model_labels_test = tf.one_hot(test_labels, depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 105,
     "status": "ok",
     "timestamp": 1637472741081,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "fBiNc5Vmo32T"
   },
   "outputs": [],
   "source": [
    "#### SAMPLE PROCESSING ####\n",
    "\n",
    "# path for preprocessed data\n",
    "full_path = f'{path}/data/sre_em/sre_em_sample.csv'\n",
    "\n",
    "# indicate which model the data will be used for\n",
    "marker_type = 'em'\n",
    "head_type = 'start'\n",
    "\n",
    "# generate inputs for model\n",
    "all_lists = generate_entity_inputs(full_path, tokenizer, marker_type, head_type, max_length=500)\n",
    "\n",
    "# SAMPLE ONLY: split into train/test\n",
    "train_all, test_all = train_test_split(all_lists)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "model_inputs_train = [x for x in train_all[0][:5]]\n",
    "model_labels_train = train_all[1]\n",
    "model_labels_train = tf.one_hot(model_labels_train, depth=2)\n",
    "\n",
    "model_inputs_test = [x for x in test_all[0][:5]]\n",
    "model_labels_test = test_all[1]\n",
    "model_labels_test = tf.one_hot(model_labels_test, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TweKc5oMo32T"
   },
   "source": [
    "#### Run Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 874333,
     "status": "ok",
     "timestamp": 1637473631834,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "3BZ9t2fvo32U",
    "outputId": "52996c72-896f-42f9-de0f-ce1fa459f31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SRE Start Entity Model ===\n",
      "BERT layer output: KerasTensor(type_spec=TensorSpec(shape=(None, 500, 768), dtype=tf.float32, name=None), name='tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0', description=\"created by layer 'tf_bert_model'\")\n",
      "Prediction: KerasTensor(type_spec=TensorSpec(shape=(None, 2), dtype=tf.float32, name=None), name='sre/Softmax:0', description=\"created by layer 'sre'\")\n",
      "\n",
      "Model: \"sre_pool\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " segment_ids (InputLayer)       [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " e1_mask (InputLayer)           [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " e2_mask (InputLayer)           [(None, 500)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]',            \n",
      "                                tentions(last_hidde               'segment_ids[0][0]']            \n",
      "                                n_state=(None, 500,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_1 (TFOpLa  (None, 500)         0           ['e1_mask[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_3 (TFOpLa  (None, 500)         0           ['e2_mask[0][0]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor (TFOpLamb  (None, 500, 768)    0           ['tf_bert_model[0][0]']          \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.count_nonzero (TFOpLam  (None,)             0           ['tf.convert_to_tensor_1[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_2 (TFOpLa  (None, 500, 768)    0           ['tf_bert_model[0][0]']          \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.count_nonzero_1 (TFOpL  (None,)             0           ['tf.convert_to_tensor_3[0][0]'] \n",
      " ambda)                                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask (Sli  (None, 768)         0           ['tf.convert_to_tensor[0][0]',   \n",
      " cingOpLambda)                                                    'tf.convert_to_tensor_1[0][0]'] \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None,)              0           ['tf.math.count_nonzero[0][0]']  \n",
      "                                                                                                  \n",
      " tf.compat.v1.boolean_mask_1 (S  (None, 768)         0           ['tf.convert_to_tensor_2[0][0]', \n",
      " licingOpLambda)                                                  'tf.convert_to_tensor_3[0][0]'] \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None,)              0           ['tf.math.count_nonzero_1[0][0]']\n",
      "                                                                                                  \n",
      " tf.RaggedTensor.from_row_lengt  (None, None, 768)   0           ['tf.compat.v1.boolean_mask[0][0]\n",
      " hs (ClassMethod)                                                ',                               \n",
      "                                                                  'tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf.RaggedTensor.from_row_lengt  (None, None, 768)   0           ['tf.compat.v1.boolean_mask_1[0][\n",
      " hs_1 (ClassMethod)                                              0]',                             \n",
      "                                                                  'tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 768)         0           ['tf.RaggedTensor.from_row_length\n",
      " da)                                                             s[0][0]']                        \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze_1 (TFOpLa  (None, 768)         0           ['tf.RaggedTensor.from_row_length\n",
      " mbda)                                                           s_1[0][0]']                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1536)         0           ['tf.compat.v1.squeeze[0][0]',   \n",
      "                                                                  'tf.compat.v1.squeeze_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          393472      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sre (Dense)                    (None, 2)            514         ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 108,704,258\n",
      "Trainable params: 108,704,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "29/29 [==============================] - 176s 6s/step - loss: 0.6341 - accuracy: 0.0000e+00 - binary_accuracy: 0.6468 - recall: 0.6468 - precision: 0.6468 - val_loss: 0.5862 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.6439 - val_recall: 0.6439 - val_precision: 0.6439\n",
      "Epoch 2/5\n",
      "29/29 [==============================] - 173s 6s/step - loss: 0.5453 - accuracy: 0.0000e+00 - binary_accuracy: 0.6865 - recall: 0.6865 - precision: 0.6865 - val_loss: 0.5064 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.7512 - val_recall: 0.7512 - val_precision: 0.7512\n",
      "Epoch 3/5\n",
      "29/29 [==============================] - 172s 6s/step - loss: 0.4844 - accuracy: 0.0000e+00 - binary_accuracy: 0.7726 - recall: 0.7726 - precision: 0.7726 - val_loss: 0.4510 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.7902 - val_recall: 0.7902 - val_precision: 0.7902\n",
      "Epoch 4/5\n",
      "29/29 [==============================] - 172s 6s/step - loss: 0.4282 - accuracy: 0.0000e+00 - binary_accuracy: 0.8433 - recall: 0.8433 - precision: 0.8433 - val_loss: 0.4000 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.8732 - val_recall: 0.8732 - val_precision: 0.8732\n",
      "Epoch 5/5\n",
      "29/29 [==============================] - 175s 6s/step - loss: 0.3927 - accuracy: 0.0000e+00 - binary_accuracy: 0.8675 - recall: 0.8675 - precision: 0.8675 - val_loss: 0.3636 - val_accuracy: 0.0000e+00 - val_binary_accuracy: 0.8878 - val_recall: 0.8878 - val_precision: 0.8878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f62fbd7c350>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### SAMPLE RUN ####\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "model = sre_start_model(bert_model, max_length)\n",
    "\n",
    "model.fit(\n",
    "    model_inputs_train, \n",
    "    {\"sre\": model_labels_train},\n",
    "    validation_data=(model_inputs_test, {\"sre\": model_labels_test}),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TRAIN/DEV RUN ####\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "model = sre_start_model(bert_model, max_length)\n",
    "\n",
    "model.fit(\n",
    "    model_inputs_train, \n",
    "    {\"sre\": model_labels_train},\n",
    "    validation_data=(model_inputs_dev, {\"sre\": model_labels_dev}),\n",
    "    epochs=5,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3rV0shhro32V",
    "outputId": "25b147ba-a456-4e5a-af1b-525e9d36a587"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: visualize model\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "executionInfo": {
     "elapsed": 9149,
     "status": "error",
     "timestamp": 1637473655893,
     "user": {
      "displayName": "Lea Cleary",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjimsJwqZyDGc9HCTSMziSaLt9DBHq1F3Odv5B9=s64",
      "userId": "16569730562812745412"
     },
     "user_tz": 300
    },
    "id": "xlKiGjCuo32W",
    "outputId": "32f38391-1c97-4b58-f6e8-4640e87e6e2e"
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model_name = 'sample'\n",
    "model.save(f'{path}/models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN-Qj8bvCPgA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "colab_sre_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

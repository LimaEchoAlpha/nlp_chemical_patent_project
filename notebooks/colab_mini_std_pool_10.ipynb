{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QJ_ExX95C8m"
   },
   "source": [
    "#### Set-up for Colab\n",
    "Install dependencies, mount drive, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo_tjwx24E-H"
   },
   "outputs": [],
   "source": [
    "#pip install -q -U tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a01FnU6G41Jv"
   },
   "outputs": [],
   "source": [
    "#pip install -q tf-models-official==2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==2.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYhBoz05pFKY"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEkMeci5rW0L"
   },
   "outputs": [],
   "source": [
    "pip install bert-for-tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRkiRSVko_DV"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qbwOc84554BS"
   },
   "outputs": [],
   "source": [
    "path = 'drive/MyDrive/MIDS/chemical_patent_cer_ee'\n",
    "# path = '..'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKnEMa6zo32N"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CckxGheg4_bq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import re\n",
    "import sys\n",
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/MIDS/chemical_patent_cer_ee/notebooks')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "from csv import reader\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "import bert\n",
    "\n",
    "from sre_inputs import *\n",
    "from train_test import *\n",
    "from sre_models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frzxEMlBo32P"
   },
   "source": [
    "#### BERT Model\n",
    "- Load BERT model and tokenizer\n",
    "- Set max length for inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ECV6hEuo32Q"
   },
   "outputs": [],
   "source": [
    "# path for bert model\n",
    "bert_model_dir = f'{path}/bert/bert_mini'\n",
    "bert_type = bert_model_dir.split('/')[-1]\n",
    "\n",
    "# set tokenizer\n",
    "vocab_file = os.path.join(bert_model_dir, \"vocab.txt\")\n",
    "tokenizer = BertTokenizer(vocab_file=vocab_file, do_lower_case=False)\n",
    "\n",
    "# set BERT model\n",
    "bert_params = bert.params_from_pretrained_ckpt(bert_model_dir)\n",
    "bert = bert.BertModelLayer.from_params(bert_params, name=\"bert\")\n",
    "\n",
    "# set max length for inputs\n",
    "max_length = 512\n",
    "\n",
    "# set parameters for model type\n",
    "marker_type = 'std' # 'em', 'ner', or 'std'\n",
    "head_type = 'pool' # 'cls', 'start', 'pool', or 'ner'\n",
    "subsampled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSF2-2aJ8m7k"
   },
   "source": [
    "#### Data\n",
    "- Upload preprocessed chemical patent file(s)\n",
    "- Use `sre_inputs` module to generate inputs for model\n",
    "- Sample only: split into train/test using `train_test` module\n",
    "- Need to one hot encode labels before using in model\n",
    "\n",
    "*NB: Make sure that preprocessed data being uploaded and parameters chosen for generating inputs **both** match the type of model it will be used for!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fBiNc5Vmo32T"
   },
   "outputs": [],
   "source": [
    "#### SAMPLE PROCESSING ####\n",
    "\n",
    "# path for preprocessed data\n",
    "if marker_type == 'em' or marker_type == 'std':\n",
    "    sample_path = f'{path}/data/sre_em/sre_em_sample.csv'\n",
    "elif marker_type == 'ner':\n",
    "    sample_path = f'{path}/data/sre_ner/sre_ner_sample.csv'\n",
    "\n",
    "# generate inputs for model\n",
    "if marker_type == 'em' or marker_type == 'ner':\n",
    "    all_lists = generate_entity_inputs(sample_path, tokenizer, marker_type, head_type, max_length)\n",
    "elif marker_type == 'std':\n",
    "    all_lists = generate_standard_inputs(sample_path, tokenizer, max_length)\n",
    "\n",
    "# SAMPLE ONLY: split into train/test\n",
    "train_all, test_all = train_test_split(all_lists)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "sample_inputs_train = [x for x in train_all[0][:5]]\n",
    "sample_labels_train = train_all[1]\n",
    "sample_labels_train = tf.one_hot(sample_labels_train, depth=3)\n",
    "\n",
    "sample_inputs_test = [x for x in test_all[0][:5]]\n",
    "sample_labels_test = test_all[1]\n",
    "sample_labels_test = tf.one_hot(sample_labels_test, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeO-o0ko-bjO"
   },
   "outputs": [],
   "source": [
    "#### TRAIN/DEV DATASET PROCESSING ####\n",
    "\n",
    "# paths for preprocessed data\n",
    "if (marker_type == 'em' or marker_type == 'std') and not subsampled:\n",
    "    train_path = f'{path}/data/sre_em/sre_em_train.csv'\n",
    "    dev_path = f'{path}/data/sre_em/sre_em_dev.csv'\n",
    "elif (marker_type == 'em' or marker_type == 'std') and subsampled:\n",
    "    train_path = f'{path}/data/sre_em/sre_em_train_subsampled.csv'\n",
    "    dev_path = f'{path}/data/sre_em/sre_em_dev_subsampled.csv'\n",
    "elif marker_type == 'ner' and not subsampled:\n",
    "    train_path = f'{path}/data/sre_ner/sre_ner_train.csv'\n",
    "    dev_path = f'{path}/data/sre_ner/sre_ner_dev.csv'\n",
    "elif marker_type == 'ner' and subsampled:\n",
    "    train_path = f'{path}/data/sre_ner/sre_ner_train_subsampled.csv'\n",
    "    dev_path = f'{path}/data/sre_ner/sre_ner_dev_subsampled.csv'\n",
    "\n",
    "print(f'Loaded {train_path}')\n",
    "print(f'Loaded {dev_path}')\n",
    "\n",
    "# generate inputs for model\n",
    "if marker_type == 'em' or marker_type == 'ner':\n",
    "    train_lists = generate_entity_inputs(train_path, tokenizer, marker_type, head_type, max_length)\n",
    "    dev_lists = generate_entity_inputs(dev_path, tokenizer, marker_type, head_type, max_length)\n",
    "elif marker_type == 'std':\n",
    "    train_lists = generate_standard_inputs(train_path, tokenizer, max_length)\n",
    "    dev_lists = generate_standard_inputs(dev_path, tokenizer, max_length)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "model_inputs_train = [x for x in train_lists[0][:5]]\n",
    "train_labels = train_lists[1]\n",
    "model_labels_train = tf.one_hot(train_labels, depth=3)\n",
    "\n",
    "model_inputs_dev = [x for x in dev_lists[0][:5]]\n",
    "dev_labels = dev_lists[1]\n",
    "model_labels_dev = tf.one_hot(dev_labels, depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "by_OKfjhrW0R"
   },
   "outputs": [],
   "source": [
    "#### TEST DATASET PROCESSING ####\n",
    "\n",
    "# path for preprocessed data\n",
    "if marker_type == 'em' or marker_type == 'std':\n",
    "    test_path = f'{path}/data/sre_em/sre_em_test.csv'\n",
    "elif marker_type == 'ner':\n",
    "    test_path = f'{path}/data/sre_ner/sre_ner_test.csv'\n",
    "\n",
    "# generate inputs for model\n",
    "if marker_type == 'em' or marker_type == 'ner':\n",
    "    test_lists = generate_entity_inputs(test_path, tokenizer, marker_type, head_type, max_length)\n",
    "elif marker_type == 'std':\n",
    "    test_lists = generate_standard_inputs(test_path, tokenizer, max_length)\n",
    "\n",
    "# generate inputs and labels\n",
    "# one hot encode labels\n",
    "model_inputs_test = [x for x in test_lists[0][:5]]\n",
    "test_labels = test_lists[1]\n",
    "model_labels_test = tf.one_hot(test_labels, depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TweKc5oMo32T"
   },
   "source": [
    "#### Run Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3BZ9t2fvo32U"
   },
   "outputs": [],
   "source": [
    "#### SAMPLE RUN ####\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "epochs = 1\n",
    "batch_size = 16\n",
    "train_layers = 0\n",
    "\n",
    "if head_type == 'cls':\n",
    "    model = sre_cls_model(bert, max_length, train_layers)\n",
    "elif head_type == 'start':\n",
    "    model = sre_start_model(bert, max_length, train_layers)\n",
    "elif head_type == 'pool':\n",
    "    model = sre_pool_model(bert, max_length, train_layers)\n",
    "elif head_type == 'ner':\n",
    "    model = sre_pool_model(bert, max_length, train_layers)\n",
    "\n",
    "if marker_type == 'std' or head_type == 'cls':\n",
    "    model.fit(\n",
    "        sample_inputs_train[:3], \n",
    "        {\"sre\": sample_labels_train},\n",
    "        validation_data=(sample_inputs_test[:3], {\"sre\": sample_labels_test}),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "else:\n",
    "    model.fit(\n",
    "        sample_inputs_train, \n",
    "        {\"sre\": sample_labels_train},\n",
    "        validation_data=(sample_inputs_test, {\"sre\": sample_labels_test}),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEgXMIZxrW0S"
   },
   "outputs": [],
   "source": [
    "#### TRAIN/DEV RUN ####\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "train_layers = 0\n",
    "\n",
    "if head_type == 'cls':\n",
    "    model = sre_cls_model(bert, max_length, train_layers)\n",
    "elif head_type == 'start':\n",
    "    model = sre_start_model(bert, max_length, train_layers)\n",
    "elif head_type == 'pool':\n",
    "    model = sre_pool_model(bert, max_length, train_layers)\n",
    "elif head_type == 'ner':\n",
    "    model = sre_pool_model(bert, max_length, train_layers)\n",
    "\n",
    "if marker_type == 'std' or head_type == 'cls':\n",
    "    model.fit(\n",
    "        model_inputs_train[:3], \n",
    "        {\"sre\": model_labels_train},\n",
    "        validation_data=(model_inputs_dev[:3], {\"sre\": model_labels_dev}),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "else:\n",
    "    model.fit(\n",
    "    model_inputs_train, \n",
    "    {\"sre\": model_labels_train},\n",
    "    validation_data=(model_inputs_dev, {\"sre\": model_labels_dev}),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test data\n",
    "print('Evaluate on test data')\n",
    "\n",
    "if marker_type == 'std' or head_type == 'cls':\n",
    "    results = model.evaluate(model_inputs_test[:3], model_labels_test, batch_size=batch_size)\n",
    "else:\n",
    "    results = model.evaluate(model_inputs_test, model_labels_test, batch_size=batch_size)\n",
    "\n",
    "# generate predictions on new data (probabilities -- the output of the last layer)\n",
    "print(\"Generate predictions for new samples\")\n",
    "\n",
    "if marker_type == 'std' or head_type == 'cls':\n",
    "    predictions = model.predict(model_inputs_test[:3])\n",
    "else: \n",
    "    predictions = model.predict(model_inputs_test)\n",
    "\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n",
    "# save stuff\n",
    "if subsampled:\n",
    "    model_name = f'SRE_{bert_type}_{marker_type}_{head_type}_sub'\n",
    "else:\n",
    "    model_name = f'SRE_{bert_type}_{marker_type}_{head_type}'\n",
    "\n",
    "# save results and predictions\n",
    "outputs = [results, predictions]\n",
    "with open(f'{path}/results/{model_name}.pickle', \"wb\") as f:\n",
    "    pickle.dump(outputs, f)\n",
    "\n",
    "# save model\n",
    "# model.save(f'{path}/models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to open saved file\n",
    "# with open(f'{path}/results/{model_name}.pickle', \"rb\") as f:\n",
    "#     saved_outputs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rV0shhro32V"
   },
   "outputs": [],
   "source": [
    "# OPTIONAL: visualize model\n",
    "#tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KN-Qj8bvCPgA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "colab_sre_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
